# План действий по доведению бэкенда до продакшена

**Дата создания:** 2024-12-19  
**Основан на:** BACKEND_AUDIT_REPORT.md  
**Текущая готовность:** 60%  
**Целевая готовность:** 100%

---

## 1. Резюме текущего состояния

Бэкенд Travel App находится в состоянии **60% готовности к продакшену**. Проект имеет прочную архитектурную основу (Clean Architecture, TypeScript, структурированное логирование), но содержит **критичные блокеры**, которые делают деплой в продакшен небезопасным.

**Основные блокеры:**
- Отсутствие защиты от злоупотреблений (Rate Limiting) — риск DDoS атак и исчерпания ресурсов
- Отсутствие валидации входных данных — риск безопасности и некорректной работы бизнес-логики
- Использование блокирующих операций в Redis (`KEYS`) — риск деградации производительности

**Ключевые направления работ:**
1. **Безопасность** — Rate Limiting, валидация входных данных, обработка ошибок
2. **Производительность** — оптимизация запросов к БД, пагинация, параллелизация
3. **Наблюдаемость** — мониторинг, метрики, логирование, трейсинг
4. **Качество** — тестовое покрытие, документация, обновление зависимостей

---

## 2. Общая стратегия

### 2.1. Принципы работы

1. **Приоритет безопасности** — сначала устраняем критические уязвимости и блокеры, затем переходим к оптимизациям
2. **Минимальные изменения** — каждое изменение изолировано и тестируется отдельно, чтобы не сломать текущую функциональность
3. **Постепенное повышение готовности** — после каждого этапа проверяем готовность и только затем переходим к следующему
4. **Параллельная работа** — задачи, не зависящие друг от друга, выполняются одновременно разными разработчиками
5. **Тестирование на каждом этапе** — после каждого изменения запускаются тесты и проверки
6. **Документирование изменений** — все изменения документируются для будущей поддержки

### 2.2. Последовательность этапов

**Этап 0** — Подготовка среды и инфраструктуры (1 день)  
**Этап 1** — Критичные проблемы (блокеры) (2-3 дня)  
**Этап 2** — Задачи высокого приоритета (3-4 дня)  
**Этап 3** — Задачи среднего приоритета и оптимизации (1-2 недели)  
**Этап 4** — Улучшения качества, мониторинг и документация (1-2 недели)

### 2.3. Критерии перехода между этапами

- **Этап 0 → Этап 1:** Среда разработки готова, тесты запускаются, нет конфликтов зависимостей
- **Этап 1 → Этап 2:** Все критичные блокеры устранены, тесты проходят, готовность ≥ 75%
- **Этап 2 → Этап 3:** Высокоприоритетные задачи выполнены, производительность улучшена, готовность ≥ 85%
- **Этап 3 → Этап 4:** Оптимизации завершены, мониторинг настроен, готовность ≥ 90%
- **Этап 4 → Продакшен:** Все критерии готовности выполнены, готовность = 100%

---

## 3. Пошаговый план по этапам

### Этап 0: Подготовка среды и инфраструктуры

**Цель:** Подготовить среду разработки, убедиться в работоспособности текущего кода, настроить инструменты для безопасного внесения изменений.

**Конкретные шаги:**

1. **Проверка текущего состояния проекта**
   - Запустить все существующие тесты (`npm test`)
   - Проверить сборку проекта (`npm run build`)
   - Убедиться, что проект запускается локально (`docker compose up backend`)
   - Проверить работу основных эндпоинтов вручную
   - **Связано с:** Общая проверка работоспособности
   - **Зависимости:** Нет

2. **Создание ветки для работы**
   - Создать feature-ветку `feature/production-readiness` от `main`
   - Убедиться, что все изменения будут коммититься в эту ветку
   - **Связано с:** Организация работы
   - **Зависимости:** Нет

3. **Настройка инструментов разработки**
   - Убедиться, что ESLint настроен и работает
   - Проверить, что TypeScript компилируется без ошибок
   - Настроить pre-commit hooks (если ещё не настроены)
   - **Связано с:** Качество кода
   - **Зависимости:** Нет

4. **Создание резервной копии текущего состояния**
   - Создать тег в git с текущим состоянием (`git tag backup-before-production-readiness`)
   - Документировать текущие значения переменных окружения
   - **Связано с:** Безопасность изменений
   - **Зависимости:** Нет

5. **Подготовка тестовой среды**
   - Убедиться, что тестовая БД доступна
   - Проверить доступность тестового Redis
   - Настроить отдельные переменные окружения для тестов
   - **Связано с:** Тестирование изменений
   - **Зависимости:** Нет

**Ожидаемый результат этапа:**
- Проект полностью работоспособен в текущем состоянии
- Среда разработки готова к внесению изменений
- Есть точка отката в случае проблем
- Все инструменты проверки кода работают

**Риски и предостережения:**
- Возможны проблемы с зависимостями при установке новых пакетов
- Тесты могут падать из-за проблем с окружением
- **Проверки:** Запустить полный набор тестов, проверить сборку, убедиться в работоспособности основных функций

---

### Этап 1: Критичные проблемы (блокеры)

**Цель:** Устранить все критические блокеры, которые делают деплой в продакшен небезопасным. После этого этапа готовность должна достичь 75-80%.

**Конкретные шаги:**

1. **Добавление Rate Limiting (Issue 1)**
   - Установить пакет `express-rate-limit`: `npm install express-rate-limit`
   - Создать файл `src/presentation/middleware/rate-limiter.ts` с базовой конфигурацией
   - Настроить общий лимит для всех API эндпоинтов (100 запросов за 15 минут с одного IP)
   - Добавить более строгие лимиты для тяжёлых эндпоинтов:
     - `/api/v1/routes/search` — 20 запросов за 15 минут
     - `/api/v1/routes/risk/assess` — 10 запросов за 15 минут
   - Интегрировать middleware в `src/index.ts` перед роутами
   - Добавить обработку ошибок rate limiting в единый формат ответов
   - Протестировать работу лимитов вручную и через тесты
   - **Связано с:** Issue 1 из BACKEND_AUDIT_REPORT.md
   - **Зависимости:** Этап 0 завершён

2. **Добавление валидации входных данных (Issue 2)**
   - Установить пакет `zod`: `npm install zod`
   - Создать директорию `src/presentation/validators/`
   - Создать схемы валидации для каждого эндпоинта:
     - `route-search.validator.ts` — для `/api/v1/routes/search`
     - `route-risk.validator.ts` — для `/api/v1/routes/risk/assess`
     - `route-details.validator.ts` — для `/api/v1/routes/details`
     - `cities.validator.ts` — для `/api/v1/cities`
   - Создать middleware `src/presentation/middleware/validation.middleware.ts` для применения схем
   - Применить валидацию ко всем контроллерам в `src/presentation/controllers/`
   - Обновить обработку ошибок валидации для единого формата
   - Добавить unit-тесты для валидаторов
   - Протестировать валидацию на некорректных данных
   - **Связано с:** Issue 2 из BACKEND_AUDIT_REPORT.md
   - **Зависимости:** Этап 0 завершён, можно делать параллельно с шагом 1

3. **Замена `KEYS` на `SCAN` в Redis (Issue 5)**
   - Изучить текущую реализацию `deleteByPattern` в `src/infrastructure/cache/RedisCacheService.ts`
   - Проверить версию клиента Redis (используется `redis` или `ioredis`)
   - Если используется `redis` v4, обновить метод `deleteByPattern` для использования `SCAN` через итерацию
   - Если используется `ioredis`, использовать `scanStream` для неблокирующего сканирования
   - Добавить обработку ошибок при сканировании
   - Добавить ограничение на количество итераций для предотвращения бесконечных циклов
   - Протестировать на большом количестве ключей (создать тестовые данные)
   - Добавить интеграционный тест для проверки работы `deleteByPattern`
   - **Связано с:** Issue 5 из BACKEND_AUDIT_REPORT.md
   - **Зависимости:** Этап 0 завершён, можно делать параллельно с шагами 1 и 2

4. **Добавление middleware для обработки ошибок (Issue 8)**
   - Создать файл `src/presentation/middleware/error-handler.ts`
   - Реализовать централизованный обработчик ошибок с поддержкой разных типов ошибок:
     - Ошибки валидации (ZodError)
     - Ошибки БД (PostgreSQL errors)
     - Ошибки Redis
     - Ошибки OData API
     - Общие ошибки приложения
   - Интегрировать с существующим логгером (`getLogger`)
   - Настроить скрытие деталей ошибок в продакшене (только общие сообщения)
   - Добавить обработчик в `src/index.ts` в конец цепочки middleware (после всех роутов)
   - Обновить существующие контроллеры для удаления дублирующейся обработки ошибок
   - Добавить unit-тесты для обработчика ошибок
   - Протестировать обработку различных типов ошибок
   - **Связано с:** Issue 8 из BACKEND_AUDIT_REPORT.md
   - **Зависимости:** Этап 0 завершён, можно делать параллельно с шагами 1-3

5. **Проверка утечек соединений с БД (Issue 6)**
   - Проверить все места использования `pool.connect()` в репозиториях
   - Убедиться, что `client.release()` вызывается в `finally` блоках
   - Проверить методы:
     - `PostgresRouteRepository.saveVirtualRoutesBatch`
     - `PostgresStopRepository.saveRealStopsBatch`
     - `PostgresFlightRepository` (если есть batch методы)
   - Добавить мониторинг количества активных соединений (логирование при превышении порога)
   - Добавить интеграционные тесты для проверки освобождения соединений
   - **Связано с:** Issue 6 из BACKEND_AUDIT_REPORT.md
   - **Зависимости:** Этап 0 завершён, можно делать параллельно с шагами 1-4

**Ожидаемый результат этапа:**
- API защищён от злоупотреблений через Rate Limiting
- Все входные данные валидируются через Zod схемы
- Redis операции не блокируют сервер
- Ошибки обрабатываются централизованно и безопасно
- Соединения с БД корректно освобождаются
- Готовность к продакшену: **75-80%**

**Риски и предостережения:**
- Rate Limiting может заблокировать легитимных пользователей при неправильной настройке
- Валидация может отклонить корректные данные при слишком строгих схемах
- Замена `KEYS` на `SCAN` может изменить поведение при большом количестве ключей
- **Проверки:** 
  - Запустить все тесты
  - Протестировать Rate Limiting вручную
  - Проверить валидацию на различных входных данных
  - Проверить работу Redis операций под нагрузкой
  - Проверить освобождение соединений с БД

---

### Этап 2: Задачи высокого приоритета

**Цель:** Устранить проблемы высокого приоритета, влияющие на производительность и масштабируемость. После этого этапа готовность должна достичь 85-90%.

**Конкретные шаги:**

1. **Замена `SELECT *` на явные поля (Issue 3)**
   - Проанализировать все репозитории в `src/infrastructure/repositories/`
   - Для каждого репозитория создать константы с списками полей:
     - `PostgresStopRepository` — константы для `stops` и `virtual_stops`
     - `PostgresRouteRepository` — константы для `routes` и `virtual_routes`
     - `PostgresFlightRepository` — константы для `flights`
     - `PostgresGraphRepository` — константы для `graphs`
   - Заменить все `SELECT *` на явное указание полей с использованием констант
   - Обновить методы маппинга (`mapRowTo*`) для работы с новыми запросами
   - Добавить TypeScript типы для гарантии соответствия полей
   - Протестировать все репозитории после изменений
   - Измерить улучшение производительности (время выполнения запросов)
   - **Связано с:** Issue 3 из BACKEND_AUDIT_REPORT.md
   - **Зависимости:** Этап 1 завершён

2. **Добавление пагинации в API (Issue 4)**
   - Определить эндпоинты, возвращающие списки:
     - `/api/v1/cities` — список городов
     - Возможные другие эндпоинты со списками
   - Создать утилиту `src/shared/utils/pagination.ts` для обработки параметров пагинации
   - Обновить контроллеры для поддержки параметров `page` и `limit`:
     - Валидация параметров (min/max значения)
     - Вычисление `offset`
     - Подсчёт общего количества записей
   - Обновить репозитории для использования `LIMIT` и `OFFSET` в SQL запросах
   - Обновить формат ответов для включения метаданных пагинации
   - Добавить unit-тесты для утилиты пагинации
   - Добавить интеграционные тесты для эндпоинтов с пагинацией
   - Протестировать пагинацию на больших объёмах данных
   - **Связано с:** Issue 4 из BACKEND_AUDIT_REPORT.md
   - **Зависимости:** Этап 1 завершён, можно делать параллельно с шагом 1

3. **Оптимизация фильтрации данных на уровне БД (Issue 9)**
   - Найти метод `findStopsForCity` в `BuildRouteUseCase.optimized.ts`
   - Создать метод `getStopsByCityName` в `PostgresStopRepository` для фильтрации на уровне БД
   - Использовать полнотекстовый поиск PostgreSQL (GIN индекс уже существует)
   - Обновить `BuildRouteUseCase` для использования нового метода репозитория
   - Удалить загрузку всех данных в память
   - Измерить улучшение производительности и потребления памяти
   - Добавить интеграционные тесты для нового метода
   - **Связано с:** Issue 9 из BACKEND_AUDIT_REPORT.md
   - **Зависимости:** Этап 1 завершён, можно делать параллельно с шагами 1-2

4. **Параллелизация запросов в циклах (Issue 7)**
   - Найти метод `buildRouteFromPath` в `BuildRouteUseCase.optimized.ts`
   - Проанализировать последовательные `await` в цикле
   - Рефакторить для использования `Promise.all` для параллельных запросов:
     - Собрать все промисы для сегментов маршрута
     - Выполнить параллельно через `Promise.all`
     - Обработать результаты
   - Установить `p-limit` для ограничения параллелизма (если необходимо)
   - Добавить обработку ошибок для параллельных запросов
   - Измерить улучшение времени выполнения
   - Добавить unit-тесты для проверки параллельности
   - Протестировать на длинных маршрутах
   - **Связано с:** Issue 7 из BACKEND_AUDIT_REPORT.md
   - **Зависимости:** Этап 1 завершён, можно делать параллельно с шагами 1-3

5. **Добавление составных индексов для частых запросов (Issue 11)**
   - Проанализировать частые запросы через `EXPLAIN ANALYZE` в PostgreSQL
   - Определить запросы, которые могут выиграть от составных индексов:
     - Поиск маршрутов по `from_stop_id` и `to_stop_id`
     - Поиск остановок по координатам и городу
     - Другие частые комбинации полей
   - Создать миграцию `004_add_composite_indexes.sql` с новыми индексами
   - Применить миграцию на тестовой БД
   - Измерить улучшение производительности запросов
   - Проверить влияние на производительность записи (индексы замедляют INSERT/UPDATE)
   - Применить миграцию на продакшен-подобной среде
   - **Связано с:** Issue 11 из BACKEND_AUDIT_REPORT.md
   - **Зависимости:** Этап 1 завершён, можно делать параллельно с шагами 1-4

**Ожидаемый результат этапа:**
- Запросы к БД оптимизированы (явные поля, индексы)
- API поддерживает пагинацию для больших объёмов данных
- Данные фильтруются на уровне БД, а не в памяти
- Параллельные запросы ускоряют обработку маршрутов
- Производительность значительно улучшена
- Готовность к продакшену: **85-90%**

**Риски и предостережения:**
- Изменение SQL запросов может привести к ошибкам, если поля не совпадают
- Пагинация может сломать существующие клиенты, ожидающие все данные сразу
- Составные индексы могут замедлить операции записи
- Параллельные запросы могут увеличить нагрузку на Redis и БД
- **Проверки:**
  - Запустить все тесты
  - Протестировать производительность до и после изменений
  - Проверить работу пагинации на различных объёмах данных
  - Проверить корректность параллельных запросов
  - Измерить влияние индексов на производительность записи

---

### Этап 3: Задачи среднего приоритета и оптимизации

**Цель:** Улучшить качество кода, обновить зависимости, оптимизировать производительность. После этого этапа готовность должна достичь 90-95%.

**Конкретные шаги:**

1. **Обновление зависимостей (Issue 10)**
   - Запустить `npm outdated` для анализа устаревших пакетов
   - Обновить patch версии всех зависимостей (`npm update`)
   - Обновить minor версии с тестированием:
     - Протестировать после каждого обновления
     - Запустить все тесты
     - Проверить работу основных функций
   - Обновить major версии поэтапно с тщательным тестированием:
     - `dotenv`: 16.6.1 → 17.2.3 (проверить изменения в API)
     - `uuid`: 9.0.1 → 13.0.0 (проверить совместимость)
     - `redis`: 4.7.1 → 5.10.0 (проверить изменения в API, особенно `SCAN`)
     - `express`: 4.21.2 → 5.1.0 (major update, требует особого внимания)
   - Обновить `@types/*` пакеты для соответствия новым версиям
   - Обновить `eslint` и связанные пакеты (может потребоваться обновление конфигурации)
   - Задокументировать breaking changes в обновлённых пакетах
   - Протестировать все функции после обновлений
   - **Связано с:** Issue 10 из BACKEND_AUDIT_REPORT.md
   - **Зависимости:** Этап 2 завершён

2. **Улучшение CORS конфигурации (Issue 14)**
   - Обновить `src/index.ts` для поддержки множественных origins
   - Добавить переменную окружения `CORS_ORIGINS` (список через запятую)
   - Реализовать функцию проверки origin с поддержкой wildcard (если необходимо)
   - Добавить логирование заблокированных origins (только в development)
   - Протестировать CORS с различными origins
   - Обновить документацию по настройке CORS
   - **Связано с:** Issue 14 из BACKEND_AUDIT_REPORT.md
   - **Зависимости:** Этап 2 завершён, можно делать параллельно с шагом 1

3. **Добавление request logging middleware (Issue 13)**
   - Создать файл `src/presentation/middleware/request-logger.ts`
   - Реализовать middleware для логирования всех HTTP запросов:
     - Метод, путь, статус код
     - Время выполнения запроса
     - IP адрес клиента
     - User-Agent (опционально)
   - Интегрировать с существующим логгером (`getLogger`)
   - Добавить middleware в `src/index.ts` перед роутами
   - Настроить уровень логирования в зависимости от окружения
   - Добавить фильтрацию чувствительных данных (пароли, токены) из логов
   - Протестировать логирование различных типов запросов
   - **Связано с:** Issue 13 из BACKEND_AUDIT_REPORT.md
   - **Зависимости:** Этап 2 завершён, можно делать параллельно с шагами 1-2

4. **Оптимизация connection pooling**
   - Проанализировать текущие настройки пула соединений в `DatabaseConfig`
   - Настроить оптимальные значения для продакшена:
     - `max` — максимальное количество соединений
     - `min` — минимальное количество соединений
     - `idleTimeoutMillis` — таймаут для неактивных соединений
     - `connectionTimeoutMillis` — таймаут для установки соединения
   - Добавить мониторинг использования пула (логирование при превышении порогов)
   - Протестировать под нагрузкой
   - Документировать рекомендации по настройке для различных нагрузок
   - **Связано с:** Общая оптимизация производительности
   - **Зависимости:** Этап 2 завершён, можно делать параллельно с шагами 1-3

5. **Рефакторинг и улучшение качества кода**
   - Провести code review всех изменений из предыдущих этапов
   - Устранить дублирование кода
   - Улучшить именование переменных и функций
   - Добавить JSDoc комментарии к публичным методам
   - Убедиться, что все ошибки обрабатываются корректно
   - Проверить соответствие код-стайлу проекта
   - Запустить ESLint и исправить все предупреждения
   - **Связано с:** Общее качество кода
   - **Зависимости:** Этап 2 завершён, можно делать параллельно с шагами 1-4

**Ожидаемый результат этапа:**
- Зависимости обновлены до актуальных версий
- CORS настроен для продакшена
- Все запросы логируются для отладки и аудита
- Connection pooling оптимизирован
- Качество кода улучшено
- Готовность к продакшену: **90-95%**

**Риски и предостережения:**
- Обновление major версий может привести к breaking changes
- CORS может заблокировать легитимные запросы при неправильной настройке
- Логирование может создать большой объём данных
- **Проверки:**
  - Запустить все тесты после каждого обновления
  - Протестировать все функции вручную
  - Проверить работу CORS с различными origins
  - Проверить объём логов и их формат
  - Протестировать connection pooling под нагрузкой

---

### Этап 4: Улучшения качества, мониторинг и документация

**Цель:** Добавить мониторинг, метрики, документацию и финальные улучшения. После этого этапа готовность должна достичь 100%.

**Конкретные шаги:**

1. **Добавление метрик и мониторинга (Issue 12)**
   - Установить `prom-client`: `npm install prom-client`
   - Создать модуль `src/shared/metrics/index.ts` для инициализации метрик
   - Добавить сбор метрик:
     - HTTP метрики (количество запросов, время ответа, статус коды)
     - Метрики БД (количество запросов, время выполнения, ошибки)
     - Метрики Redis (количество операций, время выполнения, ошибки)
     - Метрики использования ресурсов (CPU, память)
   - Создать endpoint `/metrics` для экспорта метрик в формате Prometheus
   - Настроить Prometheus для сбора метрик (если доступен)
   - Создать базовые Grafana дашборды (если доступен)
   - Добавить алерты для критичных метрик (высокая ошибка, медленные запросы)
   - Протестировать сбор и экспорт метрик
   - **Связано с:** Issue 12 из BACKEND_AUDIT_REPORT.md
   - **Зависимости:** Этап 3 завершён

2. **Улучшение health checks**
   - Расширить существующий `/health` endpoint:
     - Проверка подключения к PostgreSQL
     - Проверка подключения к Redis
     - Проверка доступности OData API (опционально)
     - Проверка доступности графа маршрутов
   - Добавить endpoint `/health/ready` для проверки готовности к обработке запросов
   - Добавить endpoint `/health/live` для проверки живости сервиса
   - Интегрировать с оркестраторами (Kubernetes, Docker Swarm)
   - Протестировать health checks при различных состояниях системы
   - **Связано с:** Улучшение наблюдаемости
   - **Зависимости:** Этап 3 завершён, можно делать параллельно с шагом 1

3. **Добавление документации API (Issue 15)**
   - Установить `swagger-jsdoc` и `swagger-ui-express`
   - Создать базовую конфигурацию Swagger в `src/presentation/swagger/config.ts`
   - Добавить JSDoc комментарии к контроллерам с описанием эндпоинтов:
     - Параметры запроса
     - Формат ответа
     - Коды ошибок
     - Примеры запросов и ответов
   - Настроить Swagger UI на `/api-docs`
   - Добавить описание схем данных (Zod схемы можно использовать для генерации)
   - Протестировать отображение документации
   - Обновить README с ссылкой на документацию API
   - **Связано с:** Issue 15 из BACKEND_AUDIT_REPORT.md
   - **Зависимости:** Этап 3 завершён, можно делать параллельно с шагами 1-2

4. **Улучшение тестового покрытия**
   - Проанализировать текущее покрытие тестами (`npm run test:coverage`)
   - Определить критические модули с низким покрытием:
     - Контроллеры
     - Use cases
     - Репозитории
     - Middleware
   - Добавить unit-тесты для недостающих модулей:
     - Тесты валидаторов
     - Тесты middleware (rate limiting, error handling, request logging)
     - Тесты утилит (пагинация, форматирование)
   - Добавить интеграционные тесты для критичных путей:
     - Поиск маршрутов
     - Оценка риска маршрута
     - Работа с кешем
   - Добавить E2E тесты для основных сценариев:
     - Полный цикл поиска маршрута
     - Обработка ошибок
   - Настроить минимальный порог покрытия в `jest.config.js` (70%+)
   - Настроить CI/CD для автоматического запуска тестов
   - **Связано с:** Общее качество и надёжность
   - **Зависимости:** Этап 3 завершён, можно делать параллельно с шагами 1-3

5. **Настройка CI/CD pipeline**
   - Создать конфигурацию CI/CD (GitHub Actions, GitLab CI, или аналогичный)
   - Настроить этапы:
     - Установка зависимостей
     - Запуск линтера
     - Запуск тестов
     - Проверка покрытия тестами
     - Сборка проекта
     - Деплой (опционально)
   - Настроить уведомления о результатах сборки
   - Протестировать pipeline на тестовой ветке
   - **Связано с:** Автоматизация процессов
   - **Зависимости:** Этап 3 завершён, можно делать параллельно с шагами 1-4

6. **Создание документации для продакшена**
   - Обновить `README.md` с инструкциями по деплою
   - Создать `DEPLOYMENT.md` с детальными инструкциями:
     - Требования к окружению
     - Переменные окружения
     - Процесс деплоя
     - Проверка работоспособности после деплоя
   - Создать `MONITORING.md` с описанием метрик и алертов
   - Создать `TROUBLESHOOTING.md` с описанием типичных проблем и решений
   - Добавить диаграммы архитектуры (если необходимо)
   - **Связано с:** Документация для операторов
   - **Зависимости:** Этап 3 завершён, можно делать параллельно с шагами 1-5

7. **Финальная проверка и оптимизация**
   - Провести нагрузочное тестирование:
     - Использовать инструменты типа `artillery` или `k6`
     - Протестировать основные эндпоинты под нагрузкой
     - Измерить производительность и найти узкие места
   - Оптимизировать найденные узкие места
   - Провести security audit:
     - Проверить на уязвимости через `npm audit`
     - Проверить конфигурацию безопасности
     - Проверить обработку чувствительных данных
   - Провести финальный code review всех изменений
   - Создать чеклист для деплоя в продакшен
   - **Связано с:** Финальная подготовка к продакшену
   - **Зависимости:** Все предыдущие шаги завершены

**Ожидаемый результат этапа:**
- Мониторинг и метрики настроены и работают
- Health checks расширены и интегрированы
- API полностью задокументирован
- Тестовое покрытие достаточное для продакшена
- CI/CD pipeline настроен и работает
- Документация для продакшена создана
- Система протестирована под нагрузкой
- Готовность к продакшену: **100%**

**Риски и предостережения:**
- Метрики могут создать дополнительную нагрузку на систему
- Swagger документация может устареть, если не обновлять её регулярно
- Нагрузочное тестирование может выявить проблемы, требующие дополнительной работы
- **Проверки:**
  - Проверить работу всех метрик
  - Протестировать health checks
  - Проверить актуальность документации
  - Запустить все тесты и убедиться в достаточном покрытии
  - Провести нагрузочное тестирование
  - Провести security audit

---

## 4. Что можно делать параллельно

### Группа 1: Безопасность и валидация
**Задачи, которые можно выполнять одновременно:**
- Добавление Rate Limiting (Этап 1, шаг 1)
- Добавление валидации входных данных (Этап 1, шаг 2)
- Добавление middleware для обработки ошибок (Этап 1, шаг 4)
- Улучшение CORS конфигурации (Этап 3, шаг 2)

**Почему можно параллельно:** Эти задачи затрагивают разные части системы (middleware, валидаторы, обработчики ошибок) и не конфликтуют друг с другом.

**Ограничения:** Валидация должна быть готова перед применением к контроллерам, но создание схем можно делать параллельно с Rate Limiting.

---

### Группа 2: Оптимизация запросов и работы с БД
**Задачи, которые можно выполнять одновременно:**
- Замена `SELECT *` на явные поля (Этап 2, шаг 1)
- Добавление пагинации (Этап 2, шаг 2)
- Оптимизация фильтрации данных на уровне БД (Этап 2, шаг 3)
- Добавление составных индексов (Этап 2, шаг 5)

**Почему можно параллельно:** Эти задачи работают с разными репозиториями и методами, изменения изолированы.

**Ограничения:** Индексы лучше добавлять после оптимизации запросов, чтобы понимать, какие индексы действительно нужны.

---

### Группа 3: Работа с Redis и кешированием
**Задачи, которые можно выполнять одновременно:**
- Замена `KEYS` на `SCAN` в Redis (Этап 1, шаг 3)
- Оптимизация connection pooling (Этап 3, шаг 4) — частично связано с Redis

**Почему можно параллельно:** Изменения в Redis изолированы и не влияют на другие части системы.

**Ограничения:** Нет.

---

### Группа 4: Настройка мониторинга и логирования
**Задачи, которые можно выполнять одновременно:**
- Добавление request logging middleware (Этап 3, шаг 3)
- Добавление метрик и мониторинга (Этап 4, шаг 1)
- Улучшение health checks (Этап 4, шаг 2)

**Почему можно параллельно:** Эти задачи добавляют наблюдаемость, но не изменяют бизнес-логику.

**Ограничения:** Request logging должен быть готов перед добавлением метрик для HTTP запросов, но можно делать параллельно.

---

### Группа 5: Документация и тестирование
**Задачи, которые можно выполнять одновременно:**
- Добавление документации API (Этап 4, шаг 3)
- Улучшение тестового покрытия (Этап 4, шаг 4)
- Создание документации для продакшена (Этап 4, шаг 6)

**Почему можно параллельно:** Документация и тесты не конфликтуют с кодом, их можно писать параллельно.

**Ограничения:** Тесты должны покрывать уже реализованный функционал, но можно писать тесты для существующего кода параллельно с документацией.

---

## 5. Что обязательно покрыть тестами

### 5.1. Критичные модули для unit-тестов

**Валидаторы (Этап 1, шаг 2):**
- Все Zod схемы валидации
- Middleware валидации
- Обработка ошибок валидации
- **Типы тестов:** Unit
- **Сценарии:**
  - Валидные данные проходят валидацию
  - Невалидные данные отклоняются с правильными сообщениями
  - Граничные значения (min/max, пустые строки, null/undefined)

**Rate Limiting (Этап 1, шаг 1):**
- Middleware rate limiting
- Различные лимиты для разных эндпоинтов
- Обработка превышения лимитов
- **Типы тестов:** Unit, Integration
- **Сценарии:**
  - Запросы в пределах лимита проходят
  - Превышение лимита блокирует запросы
  - Лимиты сбрасываются после истечения окна
  - Разные лимиты для разных эндпоинтов

**Обработчик ошибок (Этап 1, шаг 4):**
- Обработка различных типов ошибок
- Форматирование ответов об ошибках
- Скрытие деталей ошибок в продакшене
- **Типы тестов:** Unit
- **Сценарии:**
  - Ошибки валидации возвращают правильный формат
  - Ошибки БД обрабатываются корректно
  - Ошибки Redis обрабатываются корректно
  - Детали ошибок скрыты в продакшене

**Рефакторинг Redis (Этап 1, шаг 3):**
- Метод `deleteByPattern` с использованием `SCAN`
- Обработка больших объёмов ключей
- Обработка ошибок при сканировании
- **Типы тестов:** Integration
- **Сценарии:**
  - Удаление ключей по паттерну работает корректно
  - Большое количество ключей обрабатывается без блокировки
  - Ошибки при сканировании обрабатываются

---

### 5.2. Критичные модули для интеграционных тестов

**Репозитории с оптимизацией запросов (Этап 2, шаг 1):**
- Все методы репозиториев после замены `SELECT *`
- Корректность маппинга данных
- Производительность запросов
- **Типы тестов:** Integration
- **Сценарии:**
  - Все методы возвращают корректные данные
  - Производительность улучшилась
  - Нет ошибок при работе с БД

**Пагинация (Этап 2, шаг 2):**
- Эндпоинты с пагинацией
- Корректность метаданных пагинации
- Работа с различными значениями page/limit
- **Типы тестов:** Integration, E2E
- **Сценарии:**
  - Пагинация работает корректно для различных объёмов данных
  - Метаданные пагинации корректны
  - Граничные случаи (первая/последняя страница, пустые результаты)

**Параллельные запросы (Этап 2, шаг 4):**
- Метод `buildRouteFromPath` с параллельными запросами
- Корректность результатов при параллельном выполнении
- Обработка ошибок в параллельных запросах
- **Типы тестов:** Integration
- **Сценарии:**
  - Параллельные запросы выполняются быстрее последовательных
  - Результаты корректны
  - Ошибки в одном запросе не ломают остальные

---

### 5.3. Критичные сценарии для E2E тестов

**Полный цикл поиска маршрута:**
- Запрос на поиск маршрута
- Валидация входных данных
- Обработка Rate Limiting
- Построение маршрута через граф
- Возврат результата
- **Типы тестов:** E2E
- **Сценарии:**
  - Успешный поиск маршрута
  - Обработка невалидных данных
  - Обработка превышения Rate Limit
  - Обработка ошибок БД/Redis

**Оценка риска маршрута:**
- Запрос на оценку риска
- Валидация входных данных
- Обработка Rate Limiting
- Выполнение оценки риска
- Возврат результата
- **Типы тестов:** E2E
- **Сценарии:**
  - Успешная оценка риска
  - Обработка невалидных данных
  - Обработка ошибок

---

### 5.4. Нагрузочное тестирование

**Сценарии для нагрузочного тестирования:**
- Множественные запросы на поиск маршрута
- Проверка работы Rate Limiting под нагрузкой
- Проверка производительности БД под нагрузкой
- Проверка работы Redis под нагрузкой
- Проверка обработки ошибок под нагрузкой
- **Инструменты:** `artillery`, `k6`, или аналогичные
- **Метрики:**
  - Время ответа (p50, p95, p99)
  - Количество ошибок
  - Использование ресурсов (CPU, память)
  - Количество активных соединений с БД

---

## 6. Критерии готовности к продакшену

### 6.1. Блокеры должны быть полностью устранены

**Обязательные требования:**
- ✅ Rate Limiting настроен и протестирован
- ✅ Валидация входных данных реализована для всех эндпоинтов
- ✅ `KEYS` заменён на `SCAN` в Redis
- ✅ Middleware для обработки ошибок реализован и протестирован
- ✅ Проверка утечек соединений с БД выполнена, все соединения освобождаются корректно

**Проверка:**
- Все тесты проходят
- Ручное тестирование подтверждает работу всех функций
- Нет критичных уязвимостей в зависимостях

---

### 6.2. Метрики и мониторинг должны быть настроены

**Обязательные требования:**
- ✅ Метрики экспортируются через `/metrics` endpoint
- ✅ Сбор метрик настроен (Prometheus или аналогичный)
- ✅ Базовые дашборды созданы (Grafana или аналогичный)
- ✅ Алерты настроены для критичных метрик:
  - Высокий процент ошибок (> 5%)
  - Медленные запросы (p95 > 1 секунды)
  - Высокое использование ресурсов (CPU > 80%, память > 80%)
  - Проблемы с БД (много активных соединений, медленные запросы)
- ✅ Health checks расширены и работают

**Проверка:**
- Метрики собираются и отображаются в дашбордах
- Алерты срабатывают при проблемах
- Health checks корректно отражают состояние системы

---

### 6.3. Минимальное покрытие тестами

**Обязательные требования:**
- ✅ Unit-тесты: покрытие ≥ 70% для критичных модулей (валидаторы, middleware, утилиты)
- ✅ Интеграционные тесты: покрытие ≥ 60% для репозиториев и use cases
- ✅ E2E тесты: покрытие основных сценариев (поиск маршрута, оценка риска)
- ✅ Все тесты проходят стабильно

**Проверка:**
- Запустить `npm run test:coverage` и проверить покрытие
- Убедиться, что все тесты проходят
- Проверить стабильность тестов (запустить несколько раз)

---

### 6.4. Регрессионные проверки должны пройти успешно

**Обязательные проверки:**
- ✅ Все существующие функции работают как раньше
- ✅ Производительность не ухудшилась (или улучшилась)
- ✅ Нет регрессий в обработке ошибок
- ✅ Нет регрессий в форматах ответов API
- ✅ Нет проблем с совместимостью с фронтендом

**Проверка:**
- Запустить все существующие тесты
- Протестировать все эндпоинты вручную
- Проверить интеграцию с фронтендом
- Сравнить производительность до и после изменений

---

### 6.5. Документация должна быть актуальной

**Обязательные требования:**
- ✅ README.md обновлён с инструкциями по деплою
- ✅ DEPLOYMENT.md создан с детальными инструкциями
- ✅ API документация (Swagger) актуальна и доступна
- ✅ Переменные окружения задокументированы
- ✅ Известные ограничения задокументированы

**Проверка:**
- Проверить актуальность документации
- Убедиться, что все инструкции корректны
- Проверить доступность Swagger UI

---

### 6.6. Безопасность

**Обязательные требования:**
- ✅ Нет критичных уязвимостей в зависимостях (`npm audit` не показывает критичные проблемы)
- ✅ Секреты не хранятся в коде
- ✅ CORS настроен корректно для продакшена
- ✅ Rate Limiting защищает от злоупотреблений
- ✅ Валидация входных данных предотвращает инъекции

**Проверка:**
- Запустить `npm audit` и устранить критичные проблемы
- Проверить, что секреты в переменных окружения
- Протестировать CORS с различными origins
- Протестировать Rate Limiting

---

### 6.7. Производительность

**Обязательные требования:**
- ✅ Время ответа API в пределах приемлемых значений (p95 < 1 секунды для большинства эндпоинтов)
- ✅ БД запросы оптимизированы (используются индексы, нет N+1 проблем)
- ✅ Redis операции не блокируют сервер
- ✅ Connection pooling настроен оптимально

**Проверка:**
- Провести нагрузочное тестирование
- Проанализировать медленные запросы через `EXPLAIN ANALYZE`
- Проверить использование индексов
- Измерить время выполнения операций

---

## 7. Список задач для трекера

### Этап 0: Подготовка

**BE-0.1** | Критичный | Инфраструктура | Проверить текущее состояние проекта (тесты, сборка, запуск) | Этап 0 | 2 часа

**BE-0.2** | Критичный | Инфраструктура | Создать ветку для работы и настроить инструменты разработки | Этап 0 | 1 час

**BE-0.3** | Критичный | Инфраструктура | Создать резервную копию текущего состояния и подготовить тестовую среду | Этап 0 | 1 час

---

### Этап 1: Критичные проблемы (блокеры)

**BE-1.1** | Критичный | Безопасность | Добавить Rate Limiting для всех API эндпоинтов | Этап 1 | 3 часа

**BE-1.2** | Критичный | Безопасность | Добавить валидацию входных данных через Zod для всех эндпоинтов | Этап 1 | 6 часов

**BE-1.3** | Критичный | Производительность | Заменить `KEYS` на `SCAN` в Redis для неблокирующих операций | Этап 1 | 2 часа

**BE-1.4** | Критичный | Обработка ошибок | Создать централизованный middleware для обработки ошибок | Этап 1 | 3 часа

**BE-1.5** | Высокий | База данных | Проверить и исправить потенциальные утечки соединений с БД | Этап 1 | 2 часа

---

### Этап 2: Задачи высокого приоритета

**BE-2.1** | Высокий | База данных | Заменить `SELECT *` на явные поля во всех репозиториях | Этап 2 | 4 часа

**BE-2.2** | Высокий | API | Добавить пагинацию для эндпоинтов, возвращающих списки | Этап 2 | 6 часов

**BE-2.3** | Высокий | База данных | Оптимизировать фильтрацию данных на уровне БД вместо памяти | Этап 2 | 4 часа

**BE-2.4** | Высокий | Производительность | Параллелизовать запросы в циклах через `Promise.all` | Этап 2 | 3 часа

**BE-2.5** | Высокий | База данных | Добавить составные индексы для частых запросов | Этап 2 | 4 часа

---

### Этап 3: Задачи среднего приоритета

**BE-3.1** | Средний | Зависимости | Обновить зависимости (patch, minor, major версии) | Этап 3 | 1 день

**BE-3.2** | Средний | Безопасность | Улучшить CORS конфигурацию для поддержки множественных origins | Этап 3 | 2 часа

**BE-3.3** | Средний | Логирование | Добавить request logging middleware для всех HTTP запросов | Этап 3 | 3 часа

**BE-3.4** | Средний | База данных | Оптимизировать connection pooling для продакшена | Этап 3 | 3 часа

**BE-3.5** | Средний | Качество кода | Провести рефакторинг и улучшение качества кода | Этап 3 | 1 день

---

### Этап 4: Улучшения качества, мониторинг и документация

**BE-4.1** | Высокий | Мониторинг | Добавить метрики и мониторинг (Prometheus, Grafana) | Этап 4 | 1 день

**BE-4.2** | Высокий | Наблюдаемость | Расширить health checks (ready, live endpoints) | Этап 4 | 4 часа

**BE-4.3** | Средний | Документация | Добавить Swagger/OpenAPI документацию для API | Этап 4 | 1 день

**BE-4.4** | Высокий | Тестирование | Улучшить тестовое покрытие (unit, integration, E2E) | Этап 4 | 2 дня

**BE-4.5** | Средний | CI/CD | Настроить CI/CD pipeline для автоматизации процессов | Этап 4 | 1 день

**BE-4.6** | Средний | Документация | Создать документацию для продакшена (DEPLOYMENT, MONITORING, TROUBLESHOOTING) | Этап 4 | 1 день

**BE-4.7** | Критичный | Финальная проверка | Провести нагрузочное тестирование и security audit | Этап 4 | 1 день

---

## 8. Итоговая оценка времени и ресурсов

### Общая оценка времени

**Этап 0:** 4 часа (1 день)  
**Этап 1:** 16 часов (2-3 дня)  
**Этап 2:** 21 час (3-4 дня)  
**Этап 3:** 2-3 дня  
**Этап 4:** 7-8 дней  

**Итого:** 15-20 рабочих дней (3-4 недели)

### Рекомендуемое распределение ресурсов

**Один разработчик:**
- Этапы 0-1: 3-4 дня (критичные блокеры)
- Этапы 2-3: 5-7 дней (оптимизации)
- Этап 4: 7-8 дней (мониторинг и документация)

**Два разработчика (параллельная работа):**
- Этапы 0-1: 2-3 дня (критичные блокеры, параллельно)
- Этапы 2-3: 3-4 дня (оптимизации, параллельно)
- Этап 4: 4-5 дней (мониторинг и документация, параллельно)

**Итого:** 9-12 рабочих дней (2-2.5 недели)

### Критический путь

Задачи, которые нельзя выполнять параллельно и которые блокируют дальнейшую работу:

1. **Этап 0** → **Этап 1** (обязательно завершить подготовку)
2. **BE-1.1** (Rate Limiting) — можно параллельно с BE-1.2
3. **BE-1.2** (Валидация) — блокирует применение к контроллерам
4. **Этап 1** → **Этап 2** (обязательно завершить блокеры)
5. **BE-2.1** (SELECT *) — желательно завершить перед BE-2.5 (индексы)
6. **Этап 2** → **Этап 3** (обязательно завершить оптимизации)
7. **Этап 3** → **Этап 4** (обязательно завершить обновления)
8. **BE-4.7** (Финальная проверка) — последний шаг перед продакшеном

---

## 9. Рекомендации по приоритизации

### Если времени мало (1 неделя)

**Минимальный набор для безопасного деплоя:**
1. BE-1.1 (Rate Limiting) — 3 часа
2. BE-1.2 (Валидация) — 6 часов
3. BE-1.3 (Redis SCAN) — 2 часа
4. BE-1.4 (Error Handler) — 3 часа
5. BE-1.5 (Утечки БД) — 2 часа

**Итого:** 16 часов (2 дня) — готовность 75-80%

### Если времени достаточно (2 недели)

**Рекомендуемый набор:**
- Все задачи Этапа 0-1 (критичные блокеры)
- Все задачи Этапа 2 (высокий приоритет)
- BE-3.1 (Обновление зависимостей)
- BE-3.3 (Request logging)
- BE-4.1 (Метрики)
- BE-4.2 (Health checks)

**Итого:** 10-12 дней — готовность 90-95%

### Если времени много (3-4 недели)

**Полный набор:**
- Все задачи всех этапов
- Полное тестовое покрытие
- Полная документация
- CI/CD pipeline
- Нагрузочное тестирование

**Итого:** 15-20 дней — готовность 100%

---

## 10. Контрольные точки (Checkpoints)

### Checkpoint 1: После Этапа 0
- ✅ Проект работоспособен
- ✅ Среда разработки готова
- ✅ Есть точка отката

### Checkpoint 2: После Этапа 1
- ✅ Все критичные блокеры устранены
- ✅ Готовность ≥ 75%
- ✅ Тесты проходят
- ✅ Можно безопасно деплоить в staging

### Checkpoint 3: После Этапа 2
- ✅ Производительность улучшена
- ✅ Готовность ≥ 85%
- ✅ Тесты проходят
- ✅ Можно тестировать под нагрузкой

### Checkpoint 4: После Этапа 3
- ✅ Зависимости обновлены
- ✅ Готовность ≥ 90%
- ✅ Качество кода улучшено
- ✅ Можно готовить к продакшену

### Checkpoint 5: После Этапа 4
- ✅ Все критерии готовности выполнены
- ✅ Готовность = 100%
- ✅ Можно деплоить в продакшен

---

**Дата создания плана:** 2024-12-19  
**Последнее обновление:** 2024-12-19  
**Статус:** Готов к выполнению

еализация плана доведения бэкенда до продакшена Этап 0: Подготовка среды и инфраструктуры Состав этапа Этап 0 включает 3 задачи: BE-0.1 — Проверить текущее состояние проекта (тесты, сборка, запуск) — 2 часа BE-0.2 — Создать ветку для работы и настроить инструменты разработки — 1 час BE-0.3 — Создать резервную копию текущего состояния и подготовить тестовую среду — 1 час Цель этапа: подготовить среду разработки, убедиться в работоспособности текущего кода, настроить инструменты для безопасного внесения изменений. BE-0.1 — Проверка текущего состояния проекта Цель задачи Оценить текущее состояние проекта перед изменениями: работоспособность, наличие тестов, успешность сборки, возможность локального запуска. Это базовая проверка для дальнейшей работы. План реализации по шагам Проверка существующих тестов Перейти в директорию backend/ Запустить npm test (или npm run test) Зафиксировать результаты: какие тесты проходят, какие падают, есть ли тесты вообще Если тесты падают — зафиксировать причины (окружение, зависимости, код) Если тестов нет — отметить это для последующих этапов Проверка сборки проекта Запустить npm run build (компиляция TypeScript) Проверить наличие ошибок компиляции Проверить наличие директории dist/ с собранными файлами Если есть ошибки — зафиксировать их и оценить критичность Проверка запуска проекта локально Проверить наличие docker-compose.yml в корне проекта Проверить наличие .env или .env.example с переменными окружения Запустить docker compose up backend (или docker-compose up backend) Дождаться полного запуска сервиса Проверить логи на ошибки подключения к БД, Redis, MinIO Зафиксировать время запуска и возможные предупреждения Проверка работы основных эндпоинтов После запуска проверить доступность health check: GET http://localhost:5000/health Проверить базовый API endpoint: GET http://localhost:5000/api/v1/ Проверить эндпоинт списка городов: GET http://localhost:5000/api/v1/cities Проверить эндпоинт поиска маршрутов (если возможно без полной настройки): GET http://localhost:5000/api/v1/routes/search?from=Якутск&to=Нерюнгри Зафиксировать статус-коды ответов и наличие ошибок Документирование результатов проверки Создать файл backend/STAGE_0_CHECKLIST.md или добавить раздел в существующую документацию Зафиксировать: Результаты тестов (количество, статус) Результаты сборки (успешна/неуспешна, ошибки) Результаты запуска (успешен/неуспешен, время запуска) Результаты проверки эндпоинтов (какие работают, какие нет) Выявленные проблемы и их критичность Проверки и тесты Критичные проверки: Проект собирается без ошибок Проект запускается локально (хотя бы частично) Health check endpoint отвечает Желательные проверки: Есть хотя бы базовые тесты Основные эндпоинты отвечают Риски: Отсутствие тестов — потребуется их написание на последующих этапах Ошибки сборки — нужно исправить перед продолжением Проблемы с запуском — могут блокировать дальнейшую работу Обновление статуса После выполнения этих шагов: Зафиксировано текущее состояние проекта Выявлены проблемы, требующие внимания Есть базовая документация состояния Статус: план реализации согласован, можно приступать к выполнению проверок. BE-0.2 — Создание ветки для работы и настройка инструментов разработки Цель задачи Организовать работу в отдельной ветке и убедиться, что инструменты разработки (ESLint, TypeScript, pre-commit hooks) настроены и работают. Это обеспечивает изоляцию изменений и контроль качества кода. План реализации по шагам Создание feature-ветки для работы Проверить текущую ветку: git branch или git status Убедиться, что находимся на актуальной версии main (или master): git checkout main и git pull Создать новую ветку: git checkout -b feature/production-readiness Проверить, что ветка создана: git branch Убедиться, что все последующие коммиты будут в этой ветке Проверка настройки ESLint Проверить наличие файла .eslintrc.js, .eslintrc.json или секции eslintConfig в package.json Проверить наличие eslint в devDependencies в package.json Запустить ESLint: npm run lint (или npx eslint src/) Зафиксировать количество предупреждений и ошибок Если ESLint не настроен — отметить для настройки (можно отложить до Этапа 3) Проверка компиляции TypeScript Проверить наличие tsconfig.json в директории backend/ Запустить проверку типов без сборки: npm run type-check (если есть) или npx tsc --noEmit Зафиксировать ошибки типизации, если они есть Если ошибок нет — TypeScript настроен корректно Проверка и настройка pre-commit hooks Проверить наличие .husky/ директории или секции husky в package.json Проверить наличие husky в devDependencies Если Husky установлен — проверить наличие pre-commit hook: .husky/pre-commit Если pre-commit hook отсутствует — создать базовый: Инициализировать Husky: npx husky install (если не установлен) Создать pre-commit hook: npx husky add .husky/pre-commit "npm run lint && npm run type-check" Если Husky не установлен — отметить для установки (можно отложить до Этапа 3, но желательно сделать сейчас) Проверка других инструментов качества кода Проверить наличие prettier (опционально, но желательно) Проверить наличие .editorconfig (опционально) Зафиксировать, какие инструменты есть, каких не хватает Документирование состояния инструментов Обновить backend/STAGE_0_CHECKLIST.md (или создать новый файл) Зафиксировать: Название созданной ветки Состояние ESLint (настроен/не настроен, количество предупреждений) Состояние TypeScript (компилируется/не компилируется, ошибки типов) Состояние pre-commit hooks (настроены/не настроены) Список отсутствующих инструментов Проверки и тесты Критичные проверки: Ветка feature/production-readiness создана и активна TypeScript компилируется без ошибок (или ошибки зафиксированы) Желательные проверки: ESLint настроен и работает Pre-commit hooks настроены Риски: Отсутствие ESLint — код может не соответствовать стандартам Отсутствие pre-commit hooks — возможны коммиты с ошибками Ошибки TypeScript — могут блокировать сборку Обновление статуса После выполнения этих шагов: Создана рабочая ветка для изоляции изменений Проверено состояние инструментов разработки Выявлены отсутствующие инструменты Статус: план реализации согласован, можно приступать к выполнению. BE-0.3 — Создание резервной копии текущего состояния и подготовка тестовой среды Цель задачи Создать точку отката на случай проблем и подготовить тестовую среду для безопасного тестирования изменений. Это обеспечивает возможность быстрого восстановления и изолированное тестирование. План реализации по шагам Создание git-тега для резервной копии Убедиться, что все текущие изменения закоммичены или находятся в рабочей ветке Проверить статус git: git status (не должно быть незакоммиченных критичных изменений) Создать тег с текущим состоянием: git tag backup-before-production-readiness Проверить, что тег создан: git tag -l Опционально: запушьте тег в удалённый репозиторий: git push origin backup-before-production-readiness (для безопасности) Документирование текущих переменных окружения Проверить наличие .env файла в директории backend/ или в корне проекта Проверить наличие .env.example файла Если .env существует — создать его копию: .env.backup (не коммитить в git) Если .env.example существует — проверить его актуальность Задокументировать в backend/STAGE_0_CHECKLIST.md: Какие переменные окружения используются Какие значения критичны для работы (БД, Redis, порты) Какие переменные отсутствуют в .env.example Проверка доступности тестовой базы данных Проверить конфигурацию тестовой БД в docker-compose.yml или в переменных окружения Если используется Docker Compose — проверить, что сервис postgres определён Проверить доступность тестовой БД: Попытаться подключиться к БД через psql или другой клиент Или проверить через health check контейнера Зафиксировать параметры подключения к тестовой БД (хост, порт, имя БД, пользователь) Проверить, что тестовая БД отделена от продакшен-подобной (если есть) Проверка доступности тестового Redis Проверить конфигурацию тестового Redis в docker-compose.yml или в переменных окружения Если используется Docker Compose — проверить, что сервис redis определён Проверить доступность тестового Redis: Попытаться подключиться через redis-cli или другой клиент Или проверить через health check контейнера Зафиксировать параметры подключения к тестовому Redis (хост, порт, пароль, если есть) Проверить, что тестовый Redis отделён от продакшен-подобного Настройка отдельных переменных окружения для тестов Проверить наличие файла .env.test или аналогичного Если файла нет — создать .env.test на основе .env.example Настроить в .env.test: Отдельные параметры подключения к тестовой БД (если используется отдельная БД для тестов) Отдельные параметры подключения к тестовому Redis Отдельные порты для тестового сервера (если необходимо) Флаги для тестового режима (например, NODE_ENV=test) Убедиться, что .env.test добавлен в .gitignore (чтобы не коммитить тестовые данные) Проверить, что тестовые скрипты в package.json используют правильные переменные окружения Проверка конфигурации тестов Проверить наличие jest.config.js или секции jest в package.json Проверить наличие тестовых скриптов в package.json: test — запуск всех тестов test:unit — запуск unit-тестов test:integration — запуск интеграционных тестов test:coverage — запуск тестов с покрытием Проверить, что тесты могут использовать отдельные переменные окружения (через dotenv или аналогичное) Финальное документирование состояния Обновить backend/STAGE_0_CHECKLIST.md: Информация о созданном теге Состояние переменных окружения Параметры подключения к тестовой БД и Redis Состояние тестовой среды Список подготовленных файлов (.env.backup, .env.test) Проверки и тесты Критичные проверки: Git-тег создан и доступен Тестовая БД доступна (или настроена для использования) Тестовый Redis доступен (или настроен для использования) Желательные проверки: Отдельные переменные окружения для тестов настроены Тестовые скрипты работают Риски: Отсутствие резервной копии — нет точки отката Использование продакшен-подобной БД для тестов — риск потери данных Неправильная настройка тестовой среды — тесты могут быть нестабильными Обновление статуса После выполнения этих шагов: Создана точка отката через git-тег Задокументированы текущие настройки окружения Подготовлена тестовая среда для безопасного тестирования Статус: план реализации согласован, можно приступать к выполнению. Резюме по результатам Этапа 0 Выполненные задачи BE-0.1 — Проверка текущего состояния проекта BE-0.2 — Создание ветки для работы и настройка инструментов разработки BE-0.3 — Создание резервной копии и подготовка тестовой среды Изменения в системе Создана рабочая ветка feature/production-readiness для изоляции изменений Создан git-тег backup-before-production-readiness как точка отката Задокументировано текущее состояние проекта в backend/STAGE_0_CHECKLIST.md Подготовлена тестовая среда (БД, Redis, переменные окружения) Проверено состояние инструментов разработки (ESLint, TypeScript, pre-commit hooks) Готовность к продакшену Готовность не изменилась (остаётся 60%), так как Этап 0 — подготовительный. Создана база для безопасного внесения изменений. Критерии перехода к Этапу 1 Согласно PRODUCTION_READINESS_PLAN.md, критерии перехода от Этапа 0 к Этапу 1: Среда разработки готова Тесты запускаются Нет конфликтов зависимостей После выполнения BE-0.1, BE-0.2 и BE-0.3 эти критерии должны быть выполнены. Если все проверки пройдены и документация создана, можно переходить к Этапу 1. Следующие шаги После завершения Этапа 0 переходим к Этапу 1: Критичные проблемы (блокеры), начиная с BE-1.1 (Добавление Rate Limiting для всех API эндпоинтов).

еализация плана доведения бэкенда до продакшена — Этап 1 Этап 1: Критичные проблемы (блокеры) Состав этапа Этап 1 включает 5 задач: BE-1.1 — Добавить Rate Limiting для всех API эндпоинтов (3 часа) BE-1.2 — Добавить валидацию входных данных через Zod для всех эндпоинтов (6 часов) BE-1.3 — Заменить KEYS на SCAN в Redis для неблокирующих операций (2 часа) BE-1.4 — Создать централизованный middleware для обработки ошибок (3 часа) BE-1.5 — Проверить и исправить потенциальные утечки соединений с БД (2 часа) Цель этапа: устранить критические блокеры, делающие деплой небезопасным. После завершения готовность должна достичь 75–80%. BE-1.1 — Добавление Rate Limiting для всех API эндпоинтов Цель задачи Закрыть риски безопасности и доступности: Защита от DDoS и злоупотреблений Предотвращение исчерпания ресурсов (CPU, память, БД) Защита пула соединений PostgreSQL от перегрузки Обеспечение доступности для легитимных пользователей Влияние на готовность: критично для продакшена. Без Rate Limiting система уязвима к атакам. План реализации по шагам Установка пакета express-rate-limit Перейти в backend/ Установить: npm install express-rate-limit Проверить версию в package.json Убедиться, что пакет добавлен в dependencies (не devDependencies) Создание базовой конфигурации Rate Limiter Создать src/presentation/middleware/rate-limiter.ts Импортировать rateLimit из express-rate-limit Создать базовый лимитер: Окно: 15 минут Максимум: 100 запросов с одного IP Сообщение об ошибке в едином формате Включить стандартные заголовки (X-RateLimit-*) Настроить обработку ошибок в формате { error: { code, message } } Создание специализированных лимитеров для тяжёлых эндпоинтов Создать лимитер для /api/v1/routes/search: Окно: 15 минут Максимум: 20 запросов Имя: routeSearchLimiter Создать лимитер для /api/v1/routes/risk/assess: Окно: 15 минут Максимум: 10 запросов Имя: routeRiskLimiter Экспортировать все лимитеры из модуля Интеграция Rate Limiting в приложение Открыть src/index.ts Импортировать базовый и специализированные лимитеры Применить базовый лимитер ко всем API эндпоинтам: Добавить middleware перед app.use('/api/${API_VERSION}', apiRoutes) Использовать app.use('/api/${API_VERSION}', generalLimiter) Применить специализированные лимитеры к конкретным роутам: В src/presentation/routes/index.ts добавить лимитеры к соответствующим роутам Использовать router.get('/routes/search', routeSearchLimiter, RouteBuilderController.searchRoute) Использовать router.post('/routes/risk/assess', routeRiskLimiter, RiskController.assessRouteRisk) Настройка переменных окружения (опционально) Добавить в .env.example: RATE_LIMIT_WINDOW_MS (по умолчанию 900000) RATE_LIMIT_MAX_REQUESTS (по умолчанию 100) RATE_LIMIT_ROUTE_SEARCH_MAX (по умолчанию 20) RATE_LIMIT_ROUTE_RISK_MAX (по умолчанию 10) Обновить конфигурацию лимитеров для использования переменных окружения Обработка ошибок Rate Limiting Убедиться, что ошибки возвращаются в едином формате: { "error": { "code": "RATE_LIMIT_EXCEEDED", "message": "Слишком много запросов, попробуйте позже" } } Проверить, что статус-код 429 (Too Many Requests) Убедиться, что заголовки X-RateLimit-* присутствуют в ответе Обновление документации Обновить README.md с информацией о Rate Limiting Задокументировать лимиты для каждого эндпоинта Указать, как настроить лимиты через переменные окружения Проверки и тесты Критичные проверки: Базовый лимитер применяется ко всем API эндпоинтам Специализированные лимитеры применяются к соответствующим эндпоинтам При превышении лимита возвращается 429 и корректное сообщение Заголовки X-RateLimit-* присутствуют в ответах Тестирование: Unit-тесты для middleware rate limiting: Запросы в пределах лимита проходят Превышение лимита блокирует запросы Лимиты сбрасываются после истечения окна Разные лимиты для разных эндпоинтов Интеграционные тесты: Послать 101 запрос к базовому эндпоинту — 101-й должен быть заблокирован Послать 21 запрос к /routes/search — 21-й должен быть заблокирован Послать 11 запросов к /routes/risk/assess — 11-й должен быть заблокирован Ручное тестирование: Проверить работу лимитов через Postman или curl Проверить заголовки в ответах Проверить, что лимиты работают для разных IP-адресов Метрики и логи: Логировать случаи превышения лимита (IP, эндпоинт, время) Отслеживать количество заблокированных запросов Риски Блокировка легитимных пользователей: Митигация: настроить разумные лимиты, использовать переменные окружения для настройки Влияние на производительность: Митигация: использовать in-memory store (по умолчанию), при необходимости Redis для распределённого лимитирования Несовместимость с существующими клиентами: Митигация: лимиты достаточно высокие, чтобы не влиять на нормальное использование Проблемы с прокси и балансировщиками: Митигация: проверить, что req.ip корректно определяется, при необходимости настроить trust proxy Обновление статуса После выполнения: Rate Limiting установлен и настроен для всех API эндпоинтов Специализированные лимиты применены к тяжёлым эндпоинтам Ошибки возвращаются в едином формате Тесты написаны и проходят Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-1.2 — Добавление валидации входных данных через Zod для всех эндпоинтов Цель задачи Закрыть риски безопасности и корректности: Предотвращение SQL-инъекций (дополнительно к parameterized queries) Предотвращение XSS через невалидированные строки Защита от некорректных данных, которые могут нарушить бизнес-логику Обеспечение консистентности входных данных Влияние на готовность: критично для продакшена. Без валидации система уязвима к атакам и ошибкам. План реализации по шагам Установка пакета Zod Перейти в backend/ Установить: npm install zod Проверить версию в package.json Убедиться, что пакет добавлен в dependencies Создание структуры для валидаторов Создать директорию src/presentation/validators/ Создать src/presentation/validators/index.ts для экспорта всех валидаторов Создание схем валидации для каждого эндпоинта Создать route-search.validator.ts для /api/v1/routes/search: Поля: from (строка, min 1, max 255), to (строка, min 1, max 255), date (опциональная строка, формат YYYY-MM-DD), passengers (опциональное число, min 1, max 100) Использовать z.coerce для преобразования типов из query-параметров Создать route-risk.validator.ts для /api/v1/routes/risk/assess: Валидация тела запроса с маршрутом Проверка обязательных полей маршрута (routeId, segments) Валидация структуры сегментов маршрута Создать route-details.validator.ts для /api/v1/routes/details: Параметр routeId (строка, обязательный) Создать cities.validator.ts для /api/v1/cities: Опциональные параметры пагинации (page, limit) Валидация числовых параметров с границами Создание универсального middleware для валидации Создать src/presentation/middleware/validation.middleware.ts Реализовать функцию validate, принимающую Zod-схему Middleware должен: Объединять req.query и req.body для валидации Вызывать schema.parse() для валидации При успехе — вызывать next() При ошибке — возвращать 400 с единым форматом: { "error": { "code": "VALIDATION_ERROR", "message": "Ошибка валидации входных данных", "details": [массив ошибок Zod] } } Обработать различные типы ошибок Zod (required, invalid_type, custom) Применение валидации к контроллерам Обновить src/presentation/routes/index.ts: Импортировать валидаторы и middleware Применить валидацию к каждому роуту перед контроллером Пример: router.get('/routes/search', validate(RouteSearchSchema), RouteBuilderController.searchRoute) Обновить контроллеры для удаления ручной валидации (если есть): RouteBuilderController.ts — удалить проверки на наличие полей RiskController.ts — удалить ручную валидацию маршрута CitiesController.ts — удалить ручную валидацию параметров Убедиться, что контроллеры полагаются на валидацию middleware Интеграция с обработчиком ошибок (если BE-1.4 уже выполнен) Убедиться, что ошибки валидации обрабатываются централизованным обработчиком ошибок Если BE-1.4 ещё не выполнен — оставить обработку в middleware, затем перенести в обработчик ошибок Создание unit-тестов для валидаторов Создать src/__tests__/validators/route-search.validator.test.ts: Тесты для валидных данных Тесты для невалидных данных (пустые строки, неверные форматы, граничные значения) Тесты для опциональных полей Создать аналогичные тесты для остальных валидаторов Убедиться, что все граничные случаи покрыты Обновление документации Обновить README.md с информацией о валидации Задокументировать схемы валидации для каждого эндпоинта Указать примеры валидных и невалидных запросов Проверки и тесты Критичные проверки: Валидация применяется ко всем эндпоинтам Невалидные данные отклоняются с кодом 400 Валидные данные проходят валидацию Ошибки возвращаются в едином формате Тестирование: Unit-тесты для каждого валидатора: Валидные данные проходят Невалидные данные отклоняются с правильными сообщениями Граничные значения (min/max, пустые строки, null/undefined) Преобразование типов (строки в числа через z.coerce) Интеграционные тесты: Отправить невалидный запрос к /routes/search — должен вернуться 400 Отправить валидный запрос — должен пройти валидацию Проверить все эндпоинты с различными невалидными данными Ручное тестирование: Проверить валидацию через Postman или curl Проверить различные комбинации валидных и невалидных данных Проверить граничные случаи Метрики и логи: Логировать случаи ошибок валидации (эндпоинт, тип ошибки) Отслеживать количество отклонённых запросов из-за валидации Риски Отклонение корректных данных из-за слишком строгих схем: Митигация: тщательно протестировать схемы, использовать z.coerce для преобразования типов Проблемы с производительностью: Митигация: валидация выполняется быстро, но при необходимости можно кешировать схемы Несовместимость с существующими клиентами: Митигация: проверить, что схемы соответствуют текущему формату запросов Дублирование логики валидации: Митигация: использовать единый middleware, не дублировать валидацию в контроллерах Обновление статуса После выполнения: Валидация через Zod реализована для всех эндпоинтов Схемы валидации созданы и протестированы Middleware валидации интегрирован в приложение Unit-тесты написаны и проходят Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-1.3 — Замена KEYS на SCAN в Redis для неблокирующих операций Цель задачи Закрыть риски производительности: Устранение блокировки Redis при использовании KEYS Предотвращение замедления всех операций с Redis Предотвращение таймаутов при большом объёме данных Обеспечение неблокирующей работы Redis Влияние на готовность: критично для продакшена. Блокирующие операции могут привести к деградации производительности. План реализации по шагам Изучение текущей реализации Открыть src/infrastructure/cache/RedisCacheService.ts Найти метод deleteByPattern Изучить текущую реализацию с использованием KEYS Зафиксировать, как метод используется в коде Определение версии клиента Redis Проверить package.json на наличие redis или ioredis Определить, какой клиент используется Проверить версию клиента Изучить документацию клиента для SCAN или scanStream Реализация метода deleteByPattern с использованием SCAN Если используется redis v4: Реализовать итеративный SCAN с курсором Использовать client.scan() в цикле до получения курсора 0 Собрать все ключи, соответствующие паттерну Удалить ключи через client.del() Если используется ioredis: Использовать scanStream для неблокирующего сканирования Обработать поток данных через события data и end Собрать ключи и удалить их батчами Добавить ограничение на количество итераций (например, максимум 1000 итераций) для предотвращения бесконечных циклов Добавить таймаут для операции (например, 30 секунд) Обработка ошибок при сканировании Добавить try-catch для обработки ошибок Redis Логировать ошибки через существующий логгер Возвращать пустой результат при ошибках (graceful degradation) Не выбрасывать исключения, чтобы не сломать основной поток Оптимизация производительности Использовать батчинг для удаления ключей (удалять по 100-1000 ключей за раз) Добавить ограничение на количество обрабатываемых ключей за один вызов (например, максимум 10000 ключей) Добавить возможность прерывания операции при превышении лимита Обновление существующих вызовов метода Найти все места, где используется deleteByPattern Убедиться, что изменения не сломают существующую логику Проверить, что метод вызывается асинхронно и не блокирует основной поток Создание интеграционных тестов Создать src/__tests__/integration/cache/redis-scan.test.ts Тесты должны: Создать большое количество тестовых ключей (1000+) Вызвать deleteByPattern с паттерном Проверить, что все ключи удалены Проверить, что операция не блокирует другие операции Redis Проверить обработку ошибок Тестирование на больших объёмах данных Создать тестовые данные с большим количеством ключей (10000+) Протестировать deleteByPattern на этих данных Измерить время выполнения и сравнить с предыдущей реализацией Убедиться, что операция не блокирует Redis Обновление документации Обновить комментарии в коде с описанием использования SCAN Задокументировать ограничения метода (максимальное количество ключей, таймаут) Указать, что метод неблокирующий Проверки и тесты Критичные проверки: Метод deleteByPattern использует SCAN вместо KEYS Операция не блокирует Redis Все ключи, соответствующие паттерну, удаляются корректно Ошибки обрабатываются gracefully Тестирование: Интеграционные тесты: Создать 1000+ тестовых ключей Вызвать deleteByPattern с паттерном Проверить, что все ключи удалены Проверить, что операция завершается за разумное время Проверить, что другие операции Redis не блокируются Нагрузочное тестирование: Создать 10000+ тестовых ключей Вызвать deleteByPattern и измерить время выполнения Проверить, что операция не приводит к таймаутам Ручное тестирование: Проверить работу метода через Redis CLI Проверить, что операция не блокирует другие команды Redis Метрики и логи: Логировать время выполнения операции Логировать количество обработанных ключей Логировать случаи ошибок Риски Изменение поведения при большом количестве ключей: Митигация: тщательно протестировать на больших объёмах данных, добавить ограничения Проблемы с производительностью при очень большом количестве ключей: Митигация: добавить ограничения на количество обрабатываемых ключей, использовать батчинг Ошибки при сканировании: Митигация: добавить обработку ошибок, graceful degradation Несовместимость с существующим кодом: Митигация: сохранить сигнатуру метода, протестировать все места использования Обновление статуса После выполнения: Метод deleteByPattern использует SCAN вместо KEYS Операция неблокирующая и протестирована Интеграционные тесты написаны и проходят Документация обновлена Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-1.4 — Создание централизованного middleware для обработки ошибок Цель задачи Закрыть риски качества и безопасности: Единообразная обработка ошибок во всём приложении Предотвращение утечки информации об ошибках в продакшене Упрощение поддержки и отладки Согласованный формат ответов об ошибках Влияние на готовность: критично для продакшена. Без централизованной обработки ошибок возможны утечки информации и несогласованные ответы. План реализации по шагам Создание базовой структуры обработчика ошибок Создать src/presentation/middleware/error-handler.ts Импортировать необходимые типы из Express (Request, Response, NextFunction, Error) Импортировать существующий логгер (getLogger из src/shared/logger/Logger.ts) Импортировать ZodError из zod (если BE-1.2 уже выполнен) Реализация обработки различных типов ошибок Обработка ошибок валидации (ZodError): Определить тип ошибки через instanceof ZodError Извлечь детали ошибок из error.issues Вернуть статус 400 с форматом: { "error": { "code": "VALIDATION_ERROR", "message": "Ошибка валидации входных данных", "details": [массив ошибок валидации] } } Обработка ошибок БД (PostgreSQL errors): Определить тип ошибки через проверку свойств (например, error.code) Обработать различные коды ошибок PostgreSQL (например, 23505 для unique violation) Вернуть статус 400 или 500 в зависимости от типа ошибки Скрыть детали ошибки в продакшене Обработка ошибок Redis: Определить тип ошибки через проверку свойств Вернуть статус 503 (Service Unavailable) для ошибок подключения Скрыть детали ошибки в продакшене Обработка ошибок OData API: Определить тип ошибки через проверку свойств Вернуть статус 502 (Bad Gateway) для ошибок внешнего API Скрыть детали ошибки в продакшене Обработка общих ошибок приложения: Обработать все остальные ошибки как общие Вернуть статус 500 (Internal Server Error) Скрыть детали ошибки в продакшене, показывать только в development Интеграция с логгером Использовать getLogger() для логирования ошибок Логировать: Тип ошибки Сообщение об ошибке Stack trace (только в development) Контекст запроса (метод, путь, IP) Использовать уровень error для критичных ошибок, warn для некритичных Настройка скрытия деталей ошибок в продакшене Проверить переменную окружения NODE_ENV В продакшене (NODE_ENV=production): Не показывать stack trace в ответе Не показывать детали внутренних ошибок Показывать только общие сообщения типа "Внутренняя ошибка сервера" В development (NODE_ENV=development): Показывать полные детали ошибок Показывать stack trace Показывать внутренние сообщения об ошибках Интеграция обработчика ошибок в приложение Открыть src/index.ts Импортировать обработчик ошибок Добавить обработчик в конец цепочки middleware (после всех роутов): Использовать app.use(errorHandler) в самом конце, после app.use('/api/${API_VERSION}', apiRoutes) Убедиться, что обработчик вызывается для всех необработанных ошибок Обновление существующих контроллеров Найти все контроллеры в src/presentation/controllers/ Удалить дублирующуюся обработку ошибок из контроллеров: RouteBuilderController.ts — удалить try-catch блоки, которые обрабатывают ошибки вручную RiskController.ts — удалить ручную обработку ошибок DiagnosticsController.ts — удалить ручную обработку ошибок CitiesController.ts — удалить ручную обработку ошибок Оставить только выбрасывание ошибок через throw new Error() или аналогичные механизмы Убедиться, что все ошибки пробрасываются в middleware обработки ошибок Создание unit-тестов для обработчика ошибок Создать src/__tests__/middleware/error-handler.test.ts Тесты должны покрывать: Обработку ошибок валидации (ZodError) Обработку ошибок БД (PostgreSQL errors) Обработку ошибок Redis Обработку ошибок OData API Обработку общих ошибок приложения Скрытие деталей ошибок в продакшене Показ деталей ошибок в development Обновление документации Обновить README.md с информацией об обработке ошибок Задокументировать формат ответов об ошибках Указать коды ошибок для каждого типа Проверки и тесты Критичные проверки: Обработчик ошибок интегрирован в приложение Все типы ошибок обрабатываются корректно Детали ошибок скрыты в продакшене Детали ошибок показываются в development Формат ответов единообразный Тестирование: Unit-тесты для обработчика ошибок: Тесты для каждого типа ошибки Тесты для скрытия деталей в продакшене Тесты для показа деталей в development Тесты для логирования ошибок Интеграционные тесты: Создать контроллер, который выбрасывает различные типы ошибок Проверить, что все ошибки обрабатываются корректно Проверить формат ответов Ручное тестирование: Проверить обработку ошибок через Postman или curl Проверить различные типы ошибок Проверить скрытие деталей в продакшене Метрики и логи: Логировать все ошибки с контекстом Отслеживать количество ошибок по типам Отслеживать частоту ошибок Риски Потеря важной информации об ошибках: Митигация: логировать полные детали ошибок, даже если они скрыты в ответе Неправильная обработка специфичных ошибок: Митигация: тщательно протестировать все типы ошибок Проблемы с производительностью: Митигация: обработка ошибок выполняется быстро, но при необходимости можно оптимизировать Несовместимость с существующим кодом: Митигация: сохранить единый формат ответов, протестировать все контроллеры Обновление статуса После выполнения: Централизованный обработчик ошибок создан и интегрирован Все типы ошибок обрабатываются корректно Детали ошибок скрыты в продакшене Unit-тесты написаны и проходят Существующие контроллеры обновлены Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-1.5 — Проверка и исправление потенциальных утечек соединений с БД Цель задачи Закрыть риски производительности и стабильности: Предотвращение исчерпания пула соединений PostgreSQL Предотвращение блокировки новых запросов Предотвращение деградации производительности Обеспечение корректного освобождения ресурсов Влияние на готовность: высокий приоритет для продакшена. Утечки соединений могут привести к полной недоступности системы. План реализации по шагам Анализ текущего использования соединений с БД Найти все места использования pool.connect() в репозиториях: Открыть src/infrastructure/repositories/ Найти все файлы, которые используют pool.connect() Зафиксировать список методов, использующих прямое подключение Проверить основные репозитории: PostgresRouteRepository.ts PostgresStopRepository.ts PostgresFlightRepository.ts PostgresGraphRepository.ts Проверка методов с batch-операциями Проверить PostgresRouteRepository.saveVirtualRoutesBatch: Убедиться, что используется транзакция (BEGIN / COMMIT / ROLLBACK) Проверить, что client.release() вызывается в finally блоке Проверить обработку ошибок и откат транзакции Проверить PostgresStopRepository.saveRealStopsBatch: Убедиться, что используется транзакция Проверить, что client.release() вызывается в finally блоке Проверить обработку ошибок Проверить другие batch-методы в репозиториях: Найти все методы с суффиксом Batch или использующие транзакции Проверить каждый метод на корректное освобождение соединений Исправление потенциальных утечек Для каждого метода с pool.connect(): Убедиться, что используется try-catch-finally блок Убедиться, что client.release() вызывается в finally блоке Убедиться, что при ошибке выполняется ROLLBACK транзакции Убедиться, что client.release() вызывается даже при ошибке Пример правильной структуры: const client = await pool.connect() try { await client.query('BEGIN') // ... операции ... await client.query('COMMIT') } catch (error) { await client.query('ROLLBACK') throw error } finally { client.release() } Добавление мониторинга количества активных соединений Открыть src/infrastructure/config/database.config.ts Добавить метод для получения статистики пула соединений: Количество активных соединений Количество простаивающих соединений Общее количество соединений Добавить логирование при превышении порогов: Логировать предупреждение, если активных соединений > 80% от максимума Логировать ошибку, если активных соединений > 95% от максимума Интегрировать мониторинг в существующий логгер Создание интеграционных тестов для проверки освобождения соединений Создать src/__tests__/integration/repositories/connection-leak.test.ts Тесты должны: Создать множество параллельных запросов к репозиториям Проверить, что количество активных соединений не растёт бесконечно Проверить, что соединения освобождаются после завершения операций Проверить, что при ошибках соединения всё равно освобождаются Использовать таймауты для обнаружения зависших соединений Проверка использования транзакций Убедиться, что все batch-операции используют транзакции Проверить, что транзакции корректно откатываются при ошибках Убедиться, что нет незавершённых транзакций Обновление документации Обновить комментарии в коде с описанием правильного использования соединений Задокументировать паттерн использования pool.connect() с транзакциями Указать важность освобождения соединений в finally блоке Проверки и тесты Критичные проверки: Все методы с pool.connect() используют finally блок для освобождения соединений Транзакции корректно откатываются при ошибках Соединения освобождаются даже при ошибках Мониторинг активных соединений работает Тестирование: Интеграционные тесты: Создать множество параллельных запросов Проверить, что соединения освобождаются Проверить, что нет утечек соединений Проверить работу при ошибках Нагрузочное тестирование: Создать высокую нагрузку на репозитории Проверить, что пул соединений не исчерпывается Проверить, что система остаётся стабильной Ручное тестирование: Проверить работу репозиториев под нагрузкой Проверить логи на предупреждения о превышении порогов Метрики и логи: Логировать количество активных соединений при превышении порогов Отслеживать случаи, когда соединения не освобождаются Мониторить использование пула соединений Риски Пропущенные места с утечками: Митигация: тщательно проверить все репозитории, использовать интеграционные тесты Проблемы с производительностью при мониторинге: Митигация: мониторинг выполняется асинхронно, не блокирует основной поток Неправильная обработка ошибок: Митигация: использовать try-catch-finally, гарантировать освобождение соединений Обновление статуса После выполнения: Все методы с pool.connect() проверены и исправлены Мониторинг активных соединений добавлен Интеграционные тесты написаны и проходят Документация обновлена Статус: план реализации согласован, можно приступать к внесению изменений в код. Резюме по результатам Этапа 1 Выполненные задачи BE-1.1 — Добавление Rate Limiting для всех API эндпоинтов BE-1.2 — Добавление валидации входных данных через Zod для всех эндпоинтов BE-1.3 — Замена KEYS на SCAN в Redis для неблокирующих операций BE-1.4 — Создание централизованного middleware для обработки ошибок BE-1.5 — Проверка и исправление потенциальных утечек соединений с БД Изменения в системе API защищён от злоупотреблений через Rate Limiting (базовые и специализированные лимиты) Все входные данные валидируются через Zod-схемы для всех эндпоинтов Redis-операции неблокирующие (использование SCAN вместо KEYS) Ошибки обрабатываются централизованно и безопасно (скрытие деталей в продакшене) Соединения с БД корректно освобождаются (мониторинг и исправление утечек) Готовность к продакшену Готовность повысилась с 60% до 75–80% (по оценке из PRODUCTION_READINESS_PLAN.md). Критичные блокеры устранены, система защищена от основных рисков безопасности и производительности. Критерии перехода к Этапу 2 Согласно PRODUCTION_READINESS_PLAN.md, критерии перехода от Этапа 1 к Этапу 2: Все критичные блокеры устранены Тесты проходят Готовность ≥ 75% После выполнения BE-1.1, BE-1.2, BE-1.3, BE-1.4 и BE-1.5 эти критерии должны быть выполнены. Если все задачи завершены, тесты проходят и готовность достигла 75–80%, можно переходить к Этапу 2. Следующие шаги После завершения Этапа 1 переходим к Этапу 2: Задачи высокого приоритета, начиная с BE-2.1 (Замена SELECT * на явные поля во всех репозиториях).

Реализация плана доведения бэкенда до продакшена — Этап 2 Этап 2: Задачи высокого приоритета Состав этапа Этап 2 включает 5 задач: BE-2.1 — Заменить SELECT * на явные поля во всех репозиториях (4 часа) BE-2.2 — Добавить пагинацию для эндпоинтов, возвращающих списки (6 часов) BE-2.3 — Оптимизировать фильтрацию данных на уровне БД вместо памяти (4 часа) BE-2.4 — Параллелизовать запросы в циклах через Promise.all (3 часа) BE-2.5 — Добавить составные индексы для частых запросов (4 часа) Цель этапа Устранить проблемы высокого приоритета, влияющие на производительность и масштабируемость: Оптимизация запросов к БД (явные поля, индексы) Поддержка пагинации для больших объёмов данных Фильтрация на уровне БД вместо памяти Параллелизация запросов для ускорения обработки После завершения готовность должна достичь 85–90%. Связь с предыдущими этапами Этап 0: подготовлена среда, есть тестовая БД и инструменты Этап 1: устранены блокеры безопасности и стабильности (Rate Limiting, валидация, обработка ошибок) Этап 2 опирается на: Валидацию входных данных (BE-1.2) — для валидации параметров пагинации Централизованную обработку ошибок (BE-1.4) — для обработки ошибок оптимизированных запросов Исправленные утечки соединений (BE-1.5) — для стабильной работы оптимизированных запросов BE-2.1 — Замена SELECT * на явные поля во всех репозиториях Цель задачи Закрыть риски производительности и поддерживаемости: Снижение объёма передаваемых данных из БД Защита от проблем при изменении схемы БД Снижение нагрузки на сеть и память Улучшение читаемости и явности запросов Влияние на готовность: высокий приоритет. Оптимизация запросов критична для масштабирования и производительности. План реализации по шагам Аудит использования SELECT * в репозиториях Открыть src/infrastructure/repositories/ Найти все вхождения SELECT * в SQL-запросах Зафиксировать для каждого репозитория: PostgresStopRepository.ts — таблицы stops и virtual_stops PostgresRouteRepository.ts — таблицы routes и virtual_routes PostgresFlightRepository.ts — таблица flights PostgresGraphRepository.ts — таблица graphs Составить список методов, использующих SELECT * Определение реальных наборов полей для каждой таблицы Изучить схемы таблиц в миграциях (src/infrastructure/database/migrations/) Для каждой таблицы определить: Все колонки Какие колонки используются в маппинге (mapRowTo*) Какие колонки нужны для бизнес-логики Убедиться, что наборы полей соответствуют TypeScript-типам сущностей Создание констант с списками полей для каждого репозитория В каждом репозитории создать константы: STOPS_FIELDS для таблицы stops VIRTUAL_STOPS_FIELDS для таблицы virtual_stops ROUTES_FIELDS для таблицы routes VIRTUAL_ROUTES_FIELDS для таблицы virtual_routes FLIGHTS_FIELDS для таблицы flights GRAPHS_FIELDS для таблицы graphs Константы должны быть массивами строк с именами полей Использовать формат: const STOPS_FIELDS = ['id', 'name', 'latitude', 'longitude', ...] Замена SELECT * на явные поля с использованием констант Для каждого метода с SELECT *: Заменить на SELECT ${STOPS_FIELDS.join(', ')} (или соответствующую константу) Убедиться, что порядок полей соответствует ожиданиям маппинга Проверить, что все необходимые поля включены Обновить все SQL-запросы во всех репозиториях Убедиться, что запросы остаются валидными Обновление методов маппинга для работы с новыми запросами Проверить методы mapRowTo* в каждом репозитории Убедиться, что маппинг корректно работает с новым порядком полей При необходимости обновить маппинг для соответствия новым запросам Проверить, что все поля маппятся корректно Добавление TypeScript-типов для гарантии соответствия полей Создать типы для каждого набора полей (опционально) Использовать TypeScript для проверки соответствия констант полей и типов сущностей Убедиться, что TypeScript компилируется без ошибок после изменений Тестирование всех репозиториев после изменений Запустить существующие тесты для каждого репозитория Убедиться, что все тесты проходят При необходимости обновить тесты для соответствия новым запросам Измерение улучшения производительности Зафиксировать время выполнения запросов до изменений (базовая метрика) Зафиксировать время выполнения запросов после изменений Сравнить результаты и зафиксировать улучшение Измерить уменьшение объёма передаваемых данных Обновление документации Обновить комментарии в коде с описанием использования констант полей Задокументировать паттерн использования явных полей вместо SELECT * Указать преимущества такого подхода Проверки и тесты Критичные проверки: Все SELECT * заменены на явные поля Все запросы остаются валидными Все методы маппинга работают корректно TypeScript компилируется без ошибок Тестирование: Unit-тесты для каждого репозитория: Все методы возвращают корректные данные Маппинг работает правильно Нет ошибок при выполнении запросов Интеграционные тесты: Проверить работу всех репозиториев с реальной БД Убедиться, что данные корректно извлекаются и маппятся Проверить производительность запросов Ручное тестирование: Проверить работу всех эндпоинтов, использующих репозитории Убедиться, что данные возвращаются корректно Метрики и логи: Измерить время выполнения запросов до и после изменений Измерить объём передаваемых данных Логировать случаи ошибок при выполнении запросов Риски Ошибки при изменении SQL-запросов: Митигация: тщательно проверить все запросы, протестировать все методы репозиториев Проблемы с порядком полей: Митигация: использовать константы для гарантии консистентности, проверить маппинг Пропущенные поля: Митигация: сравнить константы полей со схемами таблиц, проверить использование полей в маппинге Деградация производительности: Митигация: измерить производительность до и после изменений, оптимизировать при необходимости Обновление статуса После выполнения: Все SELECT * заменены на явные поля во всех репозиториях Созданы константы полей для переиспользования Методы маппинга обновлены и работают корректно Тесты написаны и проходят Производительность улучшена Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-2.2 — Добавление пагинации для эндпоинтов, возвращающих списки Цель задачи Закрыть риски производительности и масштабируемости: Предотвращение больших ответов API при большом объёме данных Снижение нагрузки на БД и сеть Ускорение ответов API Предотвращение таймаутов при больших объёмах данных Влияние на готовность: высокий приоритет. Пагинация критична для работы с большими объёмами данных. План реализации по шагам Определение эндпоинтов, возвращающих списки Проанализировать все контроллеры в src/presentation/controllers/ Определить эндпоинты, возвращающие массивы данных: /api/v1/cities — список городов (CitiesController) Возможные другие эндпоинты со списками (если есть) Зафиксировать список эндпоинтов для добавления пагинации Создание утилиты для обработки параметров пагинации Создать src/shared/utils/pagination.ts Реализовать функцию для обработки параметров page и limit: Валидация параметров (min/max значения) Вычисление offset на основе page и limit Валидация граничных значений (page >= 1, limit в разумных пределах) Реализовать функцию для создания метаданных пагинации: Текущая страница Размер страницы (limit) Общее количество записей Общее количество страниц Наличие следующей/предыдущей страницы Обновление контроллеров для поддержки параметров пагинации Обновить CitiesController.ts: Извлечь параметры page и limit из req.query Использовать утилиту пагинации для валидации и вычисления offset Передать параметры пагинации в репозиторий Получить общее количество записей для метаданных Вернуть данные с метаданными пагинации Обновить другие контроллеры со списками (если есть): Применить аналогичную логику Убедиться, что формат ответа единообразный Обновление репозиториев для использования LIMIT и OFFSET Обновить PostgresStopRepository.ts (или соответствующий репозиторий для городов): Добавить параметры limit и offset в методы, возвращающие списки Использовать LIMIT и OFFSET в SQL-запросах Добавить метод для подсчёта общего количества записей (для метаданных) Обновить другие репозитории со списками (если есть): Применить аналогичную логику Убедиться, что запросы оптимизированы Обновление формата ответов для включения метаданных пагинации Определить единый формат ответа с пагинацией: { "data": [...], "pagination": { "page": 1, "limit": 50, "total": 1000, "totalPages": 20, "hasNext": true, "hasPrev": false } } Обновить все контроллеры для использования этого формата Убедиться, что формат единообразный для всех эндпоинтов Валидация параметров пагинации через Zod (опционально, если BE-1.2 выполнен) Создать Zod-схему для параметров пагинации: page: число, min 1, по умолчанию 1 limit: число, min 1, max 100, по умолчанию 50 Применить валидацию через middleware (если BE-1.2 выполнен) Или добавить валидацию в утилиту пагинации Создание unit-тестов для утилиты пагинации Создать src/__tests__/utils/pagination.test.ts Тесты должны покрывать: Валидацию параметров (min/max значения) Вычисление offset Создание метаданных пагинации Граничные случаи (первая/последняя страница, пустые результаты) Создание интеграционных тестов для эндпоинтов с пагинацией Создать src/__tests__/integration/controllers/cities-pagination.test.ts Тесты должны покрывать: Работу пагинации на различных объёмах данных Корректность метаданных пагинации Граничные случаи (первая/последняя страница, пустые результаты) Валидацию параметров пагинации Тестирование пагинации на больших объёмах данных Создать тестовые данные с большим количеством записей (10000+) Протестировать пагинацию на этих данных Убедиться, что производительность приемлема Измерить время выполнения запросов Обновление документации Обновить README.md с информацией о пагинации Задокументировать параметры пагинации для каждого эндпоинта Указать формат ответа с метаданными пагинации Указать значения по умолчанию для параметров Проверки и тесты Критичные проверки: Пагинация работает для всех эндпоинтов со списками Параметры пагинации валидируются корректно Метаданные пагинации корректны Формат ответа единообразный Тестирование: Unit-тесты для утилиты пагинации: Валидация параметров Вычисление offset Создание метаданных Граничные случаи Интеграционные тесты: Работа пагинации на различных объёмах данных Корректность метаданных Граничные случаи Ручное тестирование: Проверить пагинацию через Postman или curl Проверить различные значения page и limit Проверить граничные случаи Метрики и логи: Измерить время выполнения запросов с пагинацией Логировать случаи использования пагинации Отслеживать производительность запросов Риски Несовместимость с существующими клиентами: Митигация: сделать пагинацию опциональной (если page/limit не указаны, возвращать все данные) или версионировать API Проблемы с производительностью при подсчёте общего количества записей: Митигация: использовать COUNT(*) эффективно, при необходимости кешировать результаты Ошибки в метаданных пагинации: Митигация: тщательно протестировать вычисление метаданных, проверить граничные случаи Проблемы с большими offset: Митигация: использовать курсорную пагинацию для очень больших offset (опционально, для будущих улучшений) Обновление статуса После выполнения: Пагинация реализована для всех эндпоинтов со списками Утилита пагинации создана и протестирована Формат ответа с метаданными единообразный Тесты написаны и проходят Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-2.3 — Оптимизация фильтрации данных на уровне БД вместо памяти Цель задачи Закрыть риски производительности и масштабируемости: Снижение потребления памяти при больших объёмах данных Ускорение работы за счёт фильтрации на уровне БД Использование индексов БД для оптимизации запросов Предотвращение проблем с производительностью при росте данных Влияние на готовность: высокий приоритет. Оптимизация фильтрации критична для работы с большими объёмами данных. План реализации по шагам Анализ текущей реализации фильтрации в памяти Найти метод findStopsForCity в BuildRouteUseCase.optimized.ts Изучить текущую реализацию: Как загружаются данные (через getAllRealStops() и getAllVirtualStops()) Как выполняется фильтрация в памяти Какие данные фильтруются Зафиксировать проблемы текущей реализации Изучение существующих индексов в БД Открыть миграции в src/infrastructure/database/migrations/ Найти индексы для таблиц stops и virtual_stops Проверить наличие GIN-индекса для полнотекстового поиска (уже должен существовать) Зафиксировать, какие индексы можно использовать для оптимизации Создание метода getStopsByCityName в PostgresStopRepository Открыть src/infrastructure/repositories/PostgresStopRepository.ts Создать новый метод getStopsByCityName(cityName: string): Promise<RealStop[]> Реализовать SQL-запрос с фильтрацией на уровне БД: Использовать WHERE для фильтрации по имени города Использовать полнотекстовый поиск PostgreSQL (GIN-индекс) для оптимизации Использовать ILIKE или полнотекстовый поиск для нечёткого поиска Реализовать маппинг результатов в сущности RealStop Оптимизация SQL-запроса для использования индексов Убедиться, что запрос использует существующие индексы При необходимости использовать EXPLAIN ANALYZE для проверки использования индексов Оптимизировать запрос для максимальной производительности Обновление BuildRouteUseCase для использования нового метода репозитория Открыть src/application/route-builder/use-cases/BuildRouteUseCase.optimized.ts Найти метод findStopsForCity Заменить загрузку всех данных и фильтрацию в памяти на вызов нового метода репозитория Убедиться, что логика работы не изменилась Удалить неиспользуемый код (загрузку всех данных) Удаление загрузки всех данных в память Найти все места, где вызываются getAllRealStops() и getAllVirtualStops() для фильтрации Заменить на использование новых методов репозитория с фильтрацией на уровне БД Удалить неиспользуемый код Измерение улучшения производительности и потребления памяти Зафиксировать время выполнения и потребление памяти до изменений Зафиксировать время выполнения и потребление памяти после изменений Сравнить результаты и зафиксировать улучшение Измерить улучшение при различных объёмах данных Создание интеграционных тестов для нового метода Создать src/__tests__/integration/repositories/stops-filter.test.ts Тесты должны покрывать: Поиск остановок по точному имени города Поиск остановок по частичному совпадению имени Поиск остановок при отсутствии результатов Производительность запросов Обновление документации Обновить комментарии в коде с описанием оптимизации Задокументировать использование фильтрации на уровне БД Указать преимущества такого подхода Проверки и тесты Критичные проверки: Фильтрация работает корректно на уровне БД Используются существующие индексы Производительность улучшена Потребление памяти снижено Тестирование: Интеграционные тесты: Поиск остановок по различным критериям Корректность результатов Производительность запросов Нагрузочное тестирование: Тестирование на больших объёмах данных Измерение производительности и потребления памяти Ручное тестирование: Проверить работу поиска остановок через API Проверить производительность при различных объёмах данных Метрики и логи: Измерить время выполнения запросов до и после изменений Измерить потребление памяти Логировать случаи использования фильтрации Риски Проблемы с производительностью при неправильной оптимизации: Митигация: использовать EXPLAIN ANALYZE для проверки использования индексов, оптимизировать запросы Ошибки в логике фильтрации: Митигация: тщательно протестировать все сценарии поиска, сравнить результаты с предыдущей реализацией Проблемы с нечётким поиском: Митигация: использовать полнотекстовый поиск PostgreSQL, протестировать различные варианты поиска Обновление статуса После выполнения: Фильтрация данных выполняется на уровне БД Загрузка всех данных в память удалена Производительность и потребление памяти улучшены Интеграционные тесты написаны и проходят Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-2.4 — Параллелизация запросов в циклах через Promise.all Цель задачи Закрыть риски производительности: Ускорение обработки маршрутов за счёт параллельных запросов Снижение времени ответа API Улучшение пользовательского опыта Оптимизация использования ресурсов Влияние на готовность: высокий приоритет. Параллелизация критична для производительности обработки маршрутов. План реализации по шагам Анализ текущей реализации последовательных запросов Найти метод buildRouteFromPath в BuildRouteUseCase.optimized.ts Изучить текущую реализацию: Как выполняются последовательные await в цикле Какие запросы выполняются для каждого сегмента маршрута Какие зависимости между запросами Зафиксировать проблемы текущей реализации Определение независимых запросов для параллелизации Проанализировать цикл в buildRouteFromPath Определить, какие запросы можно выполнять параллельно: Запросы к графу для получения весов рёбер Запросы к графу для получения метаданных рёбер Запросы к репозиторию рейсов для получения рейсов между остановками Убедиться, что запросы независимы и могут выполняться параллельно Рефакторинг для использования Promise.all Собрать все промисы для сегментов маршрута в массив Использовать Promise.all для параллельного выполнения всех запросов Обработать результаты после завершения всех запросов Убедиться, что порядок результатов соответствует порядку сегментов Обработка ошибок для параллельных запросов Добавить обработку ошибок для Promise.all: Если один запрос падает, Promise.all отклонит весь промис Решить, как обрабатывать частичные ошибки (например, использовать Promise.allSettled) Убедиться, что ошибки логируются корректно Убедиться, что ошибки обрабатываются централизованным обработчиком ошибок (если BE-1.4 выполнен) Ограничение параллелизма (опционально) Установить p-limit для ограничения параллелизма (если необходимо) Настроить максимальное количество параллельных запросов Убедиться, что ограничение не снижает производительность Измерение улучшения времени выполнения Зафиксировать время выполнения до изменений Зафиксировать время выполнения после изменений Сравнить результаты и зафиксировать улучшение Измерить улучшение при различных длинах маршрутов Создание unit-тестов для проверки параллельности Создать src/__tests__/application/route-builder/parallel-requests.test.ts Тесты должны покрывать: Параллельное выполнение запросов Корректность результатов при параллельном выполнении Обработку ошибок в параллельных запросах Ограничение параллелизма (если используется) Тестирование на длинных маршрутах Создать тестовые данные с длинными маршрутами (10+ сегментов) Протестировать параллелизацию на этих данных Убедиться, что производительность улучшена Измерить время выполнения Обновление документации Обновить комментарии в коде с описанием параллелизации Задокументировать использование Promise.all для оптимизации Указать преимущества такого подхода Проверки и тесты Критичные проверки: Запросы выполняются параллельно Результаты корректны Ошибки обрабатываются правильно Производительность улучшена Тестирование: Unit-тесты: Параллельное выполнение запросов Корректность результатов Обработка ошибок Интеграционные тесты: Работа параллелизации на реальных данных Производительность при различных длинах маршрутов Ручное тестирование: Проверить работу построения маршрутов через API Проверить производительность при различных длинах маршрутов Метрики и логи: Измерить время выполнения до и после изменений Логировать случаи использования параллелизации Отслеживать производительность запросов Риски Увеличение нагрузки на Redis и БД: Митигация: использовать ограничение параллелизма, мониторить нагрузку Проблемы с порядком результатов: Митигация: сохранить порядок результатов, протестировать корректность Ошибки в параллельных запросах: Митигация: использовать Promise.allSettled для обработки частичных ошибок, логировать все ошибки Обновление статуса После выполнения: Запросы в циклах параллелизованы через Promise.all Ошибки обрабатываются корректно Производительность улучшена Unit-тесты написаны и проходят Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-2.5 — Добавление составных индексов для частых запросов Цель задачи Закрыть риски производительности: Ускорение частых запросов за счёт составных индексов Снижение нагрузки на CPU БД Улучшение производительности поиска маршрутов Оптимизация работы с большими объёмами данных Влияние на готовность: высокий приоритет. Индексы критичны для производительности запросов к БД. План реализации по шагам Анализ частых запросов через EXPLAIN ANALYZE Подключиться к тестовой БД Выполнить EXPLAIN ANALYZE для частых запросов: Поиск маршрутов по from_stop_id и to_stop_id Поиск остановок по координатам и городу Другие частые комбинации полей Зафиксировать запросы, которые могут выиграть от составных индексов Зафиксировать текущее время выполнения запросов Определение запросов для составных индексов Проанализировать результаты EXPLAIN ANALYZE Определить запросы, которые выполняются медленно и могут выиграть от индексов: Поиск маршрутов по from_stop_id и to_stop_id (вместе) Поиск остановок по координатам и городу (если часто используется вместе) Другие частые комбинации полей Зафиксировать список запросов для оптимизации Создание миграции с составными индексами Создать src/infrastructure/database/migrations/004_add_composite_indexes.sql Добавить составные индексы для определённых запросов: Индекс для routes(from_stop_id, to_stop_id) — для поиска маршрутов Индекс для stops(city_id, latitude, longitude) — для поиска остановок (если необходимо) Другие составные индексы по результатам анализа Использовать CREATE INDEX IF NOT EXISTS для безопасного создания индексов Добавить комментарии к индексам с описанием их назначения Применение миграции на тестовой БД Запустить миграцию на тестовой БД Убедиться, что индексы созданы успешно Проверить, что индексы используются в запросах через EXPLAIN ANALYZE Измерение улучшения производительности запросов Выполнить EXPLAIN ANALYZE для оптимизированных запросов Сравнить время выполнения до и после создания индексов Зафиксировать улучшение производительности Убедиться, что индексы используются в запросах Проверка влияния на производительность записи Протестировать операции INSERT и UPDATE на таблицах с новыми индексами Измерить время выполнения операций записи Убедиться, что влияние на производительность записи приемлемо При необходимости оптимизировать индексы Применение миграции на продакшен-подобной среде Применить миграцию на продакшен-подобной среде (если доступна) Убедиться, что миграция выполняется успешно Проверить, что индексы созданы и работают корректно Обновление документации Обновить комментарии в миграции с описанием индексов Задокументировать назначение каждого индекса Указать, какие запросы оптимизируются каждым индексом Проверки и тесты Критичные проверки: Индексы созданы успешно Индексы используются в запросах Производительность запросов улучшена Влияние на производительность записи приемлемо Тестирование: Интеграционные тесты: Проверить работу запросов с новыми индексами Измерить производительность запросов Проверить использование индексов через EXPLAIN ANALYZE Нагрузочное тестирование: Тестирование запросов под нагрузкой Измерение производительности операций записи Ручное тестирование: Проверить работу запросов через API Проверить производительность при различных объёмах данных Метрики и логи: Измерить время выполнения запросов до и после создания индексов Логировать случаи использования индексов Отслеживать производительность операций записи Риски Замедление операций записи: Митигация: измерить влияние на производительность записи, оптимизировать индексы при необходимости Проблемы с размером индексов: Митигация: мониторить размер индексов, оптимизировать при необходимости Неправильный выбор полей для индексов: Митигация: использовать EXPLAIN ANALYZE для проверки использования индексов, тестировать на реальных данных Обновление статуса После выполнения: Составные индексы созданы для частых запросов Производительность запросов улучшена Влияние на производительность записи проверено и приемлемо Миграция применена и протестирована Статус: план реализации согласован, можно приступать к внесению изменений в код. Резюме по результатам Этапа 2 Выполненные задачи BE-2.1 — Замена SELECT * на явные поля во всех репозиториях BE-2.2 — Добавление пагинации для эндпоинтов, возвращающих списки BE-2.3 — Оптимизация фильтрации данных на уровне БД вместо памяти BE-2.4 — Параллелизация запросов в циклах через Promise.all BE-2.5 — Добавление составных индексов для частых запросов Изменения в системе Запросы к БД оптимизированы: явные поля вместо SELECT *, составные индексы для частых запросов API поддерживает пагинацию для больших объёмов данных: эндпоинты со списками возвращают данные с метаданными пагинации Данные фильтруются на уровне БД: удалена загрузка всех данных в память, используется полнотекстовый поиск PostgreSQL Параллельные запросы ускоряют обработку маршрутов: циклы с последовательными await заменены на Promise.all Производительность улучшена: время ответа API снижено, нагрузка на БД и память уменьшена Готовность к продакшену Готовность повысилась с 75–80% до 85–90% (по оценке из PRODUCTION_READINESS_PLAN.md). Высокоприоритетные задачи выполнены, производительность и масштабируемость улучшены. Критерии перехода к Этапу 3 Согласно PRODUCTION_READINESS_PLAN.md, критерии перехода от Этапа 2 к Этапу 3: Высокоприоритетные задачи выполнены Производительность улучшена Готовность ≥ 85% После выполнения BE-2.1, BE-2.2, BE-2.3, BE-2.4 и BE-2.5 эти критерии должны быть выполнены. Если все задачи завершены, тесты проходят и готовность достигла 85–90%, можно переходить к Этапу 3. Следующие шаги После завершения Этапа 2 переходим к Этапу 3: Задачи среднего приоритета и оптимизации, начиная с BE-3.1 (Обновление зависимостей).

Реализация плана доведения бэкенда до продакшена — Этап 3 Этап 3: Задачи среднего приоритета и оптимизации Состав этапа Этап 3 включает 5 задач: BE-3.1 — Обновить зависимости (patch, minor, major версии) (1 день) BE-3.2 — Улучшить CORS конфигурацию для поддержки множественных origins (2 часа) BE-3.3 — Добавить request logging middleware для всех HTTP запросов (3 часа) BE-3.4 — Оптимизировать connection pooling для продакшена (3 часа) BE-3.5 — Провести рефакторинг и улучшение качества кода (1 день) Цель этапа Улучшить стабильность, наблюдаемость и качество кода: Повышение стабильности и надёжности через обновление зависимостей и устранение уязвимостей Улучшение наблюдаемости через логирование запросов и мониторинг Снижение технического долга через обновление зависимостей и рефакторинг Улучшение качества документации и читаемости кода После завершения готовность должна достичь 90–95%. Связь с предыдущими этапами Этап 0: подготовлена среда, есть тестовая БД и инструменты Этап 1: устранены блокеры безопасности и стабильности (Rate Limiting, валидация, обработка ошибок) Этап 2: оптимизированы запросы к БД, добавлена пагинация, улучшена производительность Этап 3 опирается на: Централизованную обработку ошибок (BE-1.4) — для логирования ошибок в request logger Валидацию входных данных (BE-1.2) — для логирования валидационных ошибок Оптимизированные запросы к БД (BE-2.1, BE-2.5) — для мониторинга производительности запросов Исправленные утечки соединений (BE-1.5) — для корректной настройки connection pooling Эти задачи выполняются после критичных и высокоприоритетных, так как они улучшают качество и наблюдаемость, но не блокируют деплой. BE-3.1 — Обновление зависимостей backend-проекта до актуальных версий Цель задачи Закрыть риски безопасности и технического долга: Устранение уязвимостей в старых версиях Получение исправлений багов Поддержка новых версий Node.js Улучшение производительности и стабильности Влияние на готовность: средний приоритет. Обновления важны для безопасности и стабильности, но не блокируют деплой, если текущие версии не имеют критичных уязвимостей. План реализации по шагам Аудит текущего состояния зависимостей Перейти в backend/ Запустить npm outdated для анализа устаревших пакетов Зафиксировать список устаревших пакетов с версиями Запустить npm audit для проверки уязвимостей Зафиксировать критичные и высокие уязвимости Создать документ с текущим состоянием зависимостей Обновление patch-версий всех зависимостей Запустить npm update для обновления patch-версий Проверить изменения в package-lock.json Запустить все тесты: npm test Проверить сборку проекта: npm run build Проверить запуск проекта локально Зафиксировать результаты обновления Обновление minor-версий с тестированием Для каждого пакета с доступной minor-версией: Обновить пакет до новой minor-версии Проверить изменения в package-lock.json Запустить все тесты: npm test Проверить сборку проекта: npm run build Проверить работу основных функций вручную Зафиксировать результаты обновления Если тесты падают или есть проблемы — откатить обновление и зафиксировать причину Обновление major-версий поэтапно с тестированием Обновить dotenv: 16.6.1 → 17.2.3 Изучить breaking changes в документации Обновить использование API в коде (если изменилось) Протестировать загрузку переменных окружения Запустить все тесты Обновить uuid: 9.0.1 → 13.0.0 Изучить breaking changes в документации Обновить использование API в коде (если изменилось) Протестировать генерацию UUID Запустить все тесты Обновить redis: 4.7.1 → 5.10.0 Изучить breaking changes в документации Особое внимание на изменения в API SCAN (если BE-1.3 уже выполнен) Обновить использование API в коде (если изменилось) Протестировать работу с Redis Запустить все тесты Обновить express: 4.21.2 → 5.1.0 Изучить breaking changes в документации Обновить использование API Express в коде (если изменилось) Протестировать работу всех эндпоинтов Запустить все тесты Особое внимание на middleware и обработку запросов Обновление @types/* пакетов Обновить все @types/* пакеты для соответствия новым версиям Проверить, что TypeScript компилируется без ошибок: npm run type-check Исправить ошибки типизации, если они появились Обновление ESLint и связанных пакетов Обновить eslint и связанные пакеты (@typescript-eslint/*) Проверить, требуется ли обновление конфигурации ESLint Обновить конфигурацию ESLint при необходимости Запустить линтер: npm run lint Исправить новые предупреждения, если они появились Документирование breaking changes Создать документ backend/DEPENDENCY_UPDATES.md Задокументировать все breaking changes в обновлённых пакетах Указать, какие изменения были внесены в код для совместимости Указать рекомендации для будущих обновлений Финальное тестирование всех функций Запустить все тесты: npm test Проверить сборку проекта: npm run build Проверить запуск проекта локально Протестировать все основные функции вручную: Поиск маршрутов Оценка риска маршрута Получение списка городов Health checks Зафиксировать результаты тестирования Проверки и тесты Критичные проверки: Все тесты проходят после обновлений Проект собирается без ошибок Проект запускается локально Основные функции работают корректно Тестирование: Unit-тесты: Все существующие unit-тесты должны проходить При необходимости обновить тесты для совместимости с новыми версиями Интеграционные тесты: Все существующие интеграционные тесты должны проходить Проверить работу с БД, Redis, внешними API Ручное тестирование: Протестировать все основные эндпоинты через Postman или curl Проверить работу всех функций Метрики и логи: Проверить, что логирование работает корректно после обновлений Проверить, что нет новых предупреждений или ошибок Риски Регрессия после обновления зависимостей: Митигация: обновлять поэтапно, тестировать после каждого обновления, использовать git для отката при проблемах Breaking changes в major-версиях: Митигация: изучить документацию по breaking changes, обновить код для совместимости, протестировать тщательно Проблемы с совместимостью: Митигация: обновлять по одному пакету, тестировать после каждого обновления, использовать тестовую среду Обновление статуса После выполнения: Все зависимости обновлены до актуальных версий Все тесты проходят Breaking changes задокументированы Проект работает корректно с новыми версиями Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-3.2 — Улучшение CORS конфигурации для поддержки множественных origins Цель задачи Закрыть риски безопасности и совместимости: Поддержка множественных origins для продакшена Гибкая настройка разрешённых origins через переменные окружения Улучшение безопасности через правильную настройку CORS Поддержка различных окружений (development, staging, production) Влияние на готовность: средний приоритет. CORS важен для продакшена, но не блокирует деплой, если текущая конфигурация работает. План реализации по шагам Анализ текущей конфигурации CORS Открыть src/index.ts Найти текущую конфигурацию CORS Изучить, как настроен CORS (один origin или несколько) Зафиксировать текущую конфигурацию Обновление конфигурации CORS для поддержки множественных origins Обновить src/index.ts для поддержки множественных origins Реализовать функцию проверки origin: Парсить список origins из переменной окружения CORS_ORIGINS (разделитель — запятая) Проверять, входит ли запрашиваемый origin в список разрешённых Поддержать wildcard для поддоменов (опционально, если необходимо) Настроить CORS middleware с функцией проверки origin Добавление переменной окружения CORS_ORIGINS Обновить .env.example: Добавить CORS_ORIGINS с примером значений (через запятую) Указать формат: CORS_ORIGINS=http://localhost:3000,https://example.com Обновить документацию по настройке переменных окружения Убедиться, что переменная окружения используется в конфигурации CORS Реализация логирования заблокированных origins Добавить логирование заблокированных origins (только в development) Использовать существующий логгер (getLogger) Логировать: Заблокированный origin Время запроса Метод и путь запроса Убедиться, что логирование не выполняется в продакшене (для безопасности) Тестирование CORS с различными origins Протестировать CORS с разрешёнными origins: Отправить запрос с разрешённого origin Проверить, что запрос проходит успешно Проверить заголовки CORS в ответе Протестировать CORS с неразрешёнными origins: Отправить запрос с неразрешённого origin Проверить, что запрос блокируется Проверить сообщение об ошибке Протестировать CORS с различными методами (GET, POST, OPTIONS) Обновление документации по настройке CORS Обновить README.md с информацией о настройке CORS Задокументировать формат переменной CORS_ORIGINS Указать примеры настройки для различных окружений Указать рекомендации по безопасности Проверки и тесты Критичные проверки: CORS работает с множественными origins Неразрешённые origins блокируются Разрешённые origins проходят успешно Логирование работает корректно (только в development) Тестирование: Интеграционные тесты: Тесты для разрешённых origins Тесты для неразрешённых origins Тесты для различных методов запросов Ручное тестирование: Проверить CORS через Postman или curl с различными origins Проверить заголовки CORS в ответах Проверить логирование заблокированных origins Метрики и логи: Логировать случаи блокировки origins (только в development) Отслеживать количество заблокированных запросов Риски Блокировка легитимных запросов при неправильной настройке: Митигация: тщательно протестировать с различными origins, использовать переменные окружения для гибкой настройки Проблемы с безопасностью при использовании wildcard: Митигация: использовать wildcard только при необходимости, тщательно протестировать безопасность Обновление статуса После выполнения: CORS настроен для поддержки множественных origins Переменная окружения CORS_ORIGINS добавлена и задокументирована Логирование заблокированных origins работает (только в development) Документация обновлена Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-3.3 — Добавление request logging middleware для всех HTTP запросов Цель задачи Закрыть риски наблюдаемости и отладки: Логирование всех HTTP-запросов для отладки и аудита Отслеживание времени выполнения запросов Улучшение диагностики проблем Поддержка аудита и мониторинга Влияние на готовность: средний приоритет. Логирование важно для продакшена, но не блокирует деплой, если текущее логирование достаточное. План реализации по шагам Создание базовой структуры request logging middleware Создать src/presentation/middleware/request-logger.ts Импортировать необходимые типы из Express (Request, Response, NextFunction) Импортировать существующий логгер (getLogger из src/shared/logger/Logger.ts) Реализация middleware для логирования HTTP-запросов Реализовать middleware для логирования всех HTTP-запросов: Зафиксировать время начала запроса Зафиксировать метод запроса (req.method) Зафиксировать путь запроса (req.path) Зафиксировать IP-адрес клиента (req.ip) Зафиксировать User-Agent (опционально, из req.headers['user-agent']) После завершения запроса: Вычислить время выполнения запроса (разница между началом и концом) Зафиксировать статус-код ответа (res.statusCode) Логировать всю информацию через существующий логгер Интеграция с существующим логгером Использовать getLogger() для логирования запросов Использовать уровень info для успешных запросов (статус < 400) Использовать уровень warn для клиентских ошибок (статус 400-499) Использовать уровень error для серверных ошибок (статус >= 500) Использовать структурированное логирование для удобства парсинга Интеграция middleware в приложение Открыть src/index.ts Импортировать request logging middleware Добавить middleware перед роутами (после CORS и других базовых middleware): Использовать app.use(requestLogger) перед app.use('/api/${API_VERSION}', apiRoutes) Убедиться, что middleware применяется ко всем запросам Настройка уровня логирования в зависимости от окружения Проверить переменную окружения NODE_ENV В development: Логировать все запросы с полной информацией Включать User-Agent и другие детали В production: Логировать только важные запросы (ошибки, медленные запросы) Исключить чувствительные данные Использовать переменную окружения LOG_LEVEL для настройки уровня логирования Фильтрация чувствительных данных из логов Определить список чувствительных полей (пароли, токены, API-ключи) Реализовать функцию фильтрации чувствительных данных: Фильтровать поля из req.body и req.query Заменять чувствительные данные на [REDACTED] Сохранять структуру данных для удобства отладки Применить фильтрацию перед логированием Тестирование логирования различных типов запросов Протестировать логирование GET-запросов Протестировать логирование POST-запросов Протестировать логирование запросов с ошибками Протестировать логирование медленных запросов Проверить формат логов Обновление документации Обновить README.md с информацией о request logging Задокументировать формат логов Указать, как настроить уровень логирования Указать рекомендации по хранению логов Проверки и тесты Критичные проверки: Все HTTP-запросы логируются Время выполнения запросов фиксируется корректно Чувствительные данные фильтруются Уровень логирования настраивается в зависимости от окружения Тестирование: Unit-тесты для middleware: Тесты для логирования различных типов запросов Тесты для фильтрации чувствительных данных Тесты для уровня логирования Интеграционные тесты: Проверить логирование запросов в реальном приложении Проверить формат логов Проверить фильтрацию чувствительных данных Ручное тестирование: Проверить логирование через Postman или curl Проверить различные типы запросов Проверить формат логов Метрики и логи: Логировать все запросы с необходимой информацией Отслеживать время выполнения запросов Отслеживать количество ошибок Риски Большой объём логов: Митигация: настроить уровень логирования в зависимости от окружения, использовать ротацию логов, рассмотреть централизованное хранение логов Проблемы с производительностью: Митигация: логирование выполняется асинхронно, не блокирует основной поток, при необходимости оптимизировать Обновление статуса После выполнения: Request logging middleware создан и интегрирован Все HTTP-запросы логируются Чувствительные данные фильтруются Уровень логирования настраивается в зависимости от окружения Тесты написаны и проходят Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-3.4 — Оптимизация connection pooling для продакшена Цель задачи Закрыть риски производительности и стабильности: Оптимизация использования пула соединений с БД Предотвращение исчерпания пула соединений Улучшение производительности за счёт оптимальных настроек Мониторинг использования пула соединений Влияние на готовность: средний приоритет. Оптимизация важна для продакшена, но не блокирует деплой, если текущие настройки работают. План реализации по шагам Анализ текущих настроек пула соединений Открыть src/infrastructure/config/database.config.ts Изучить текущие настройки пула соединений: max — максимальное количество соединений min — минимальное количество соединений (если настроено) idleTimeoutMillis — таймаут для неактивных соединений connectionTimeoutMillis — таймаут для установки соединения Зафиксировать текущие значения Определение оптимальных значений для продакшена Изучить рекомендации по настройке пула соединений для PostgreSQL Учесть: Ожидаемую нагрузку на систему Количество одновременных запросов Ресурсы сервера БД Типичные паттерны использования Определить оптимальные значения: max: обычно 20-50 соединений для средних нагрузок min: обычно 2-5 соединений для поддержания минимального пула idleTimeoutMillis: обычно 30000-60000 мс connectionTimeoutMillis: обычно 5000-10000 мс Настройка оптимальных значений для продакшена Обновить src/infrastructure/config/database.config.ts: Добавить переменные окружения для настройки пула: DB_POOL_MAX (по умолчанию 20) DB_POOL_MIN (по умолчанию 2) DB_POOL_IDLE_TIMEOUT (по умолчанию 30000) DB_POOL_CONNECTION_TIMEOUT (по умолчанию 5000) Использовать переменные окружения для настройки пула Обновить значения по умолчанию для продакшена Добавление мониторинга использования пула Добавить метод для получения статистики пула соединений: Количество активных соединений Количество простаивающих соединений Общее количество соединений Количество ожидающих запросов (если доступно) Добавить логирование при превышении порогов: Логировать предупреждение, если активных соединений > 80% от максимума Логировать ошибку, если активных соединений > 95% от максимума Интегрировать мониторинг с существующим логгером Обновление переменных окружения Обновить .env.example: Добавить переменные для настройки пула соединений Указать рекомендуемые значения для различных окружений Обновить документацию по настройке переменных окружения Тестирование под нагрузкой Создать тестовый сценарий с высокой нагрузкой: Множественные параллельные запросы к БД Длительные запросы Различные паттерны использования Протестировать работу пула соединений под нагрузкой: Проверить, что пул не исчерпывается Проверить, что соединения освобождаются корректно Проверить мониторинг использования пула Измерить производительность и стабильность Документирование рекомендаций по настройке Создать документ backend/DATABASE_POOL_CONFIG.md Задокументировать рекомендации по настройке пула соединений: Для различных нагрузок (низкая, средняя, высокая) Для различных окружений (development, staging, production) Для различных размеров серверов БД Указать, как мониторить использование пула Указать, как диагностировать проблемы с пулом Проверки и тесты Критичные проверки: Пул соединений настроен оптимально Мониторинг использования пула работает Соединения освобождаются корректно Производительность улучшена Тестирование: Интеграционные тесты: Тесты для работы пула соединений под нагрузкой Тесты для мониторинга использования пула Тесты для освобождения соединений Нагрузочное тестирование: Тестирование под высокой нагрузкой Измерение производительности и стабильности Проверка, что пул не исчерпывается Ручное тестирование: Проверить работу пула соединений через мониторинг Проверить логи на предупреждения о превышении порогов Метрики и логи: Логировать статистику пула соединений при превышении порогов Отслеживать использование пула соединений Мониторить производительность запросов к БД Риски Неправильная настройка пула соединений: Митигация: использовать рекомендации по настройке, тестировать под нагрузкой, мониторить использование пула Проблемы с производительностью при слишком малом пуле: Митигация: настроить оптимальные значения, мониторить использование пула, увеличить при необходимости Обновление статуса После выполнения: Connection pooling оптимизирован для продакшена Мониторинг использования пула добавлен Рекомендации по настройке задокументированы Тестирование под нагрузкой выполнено Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-3.5 — Рефакторинг и улучшение качества кода Цель задачи Закрыть риски поддерживаемости и качества: Устранение дублирования кода Улучшение читаемости и понимания кода Добавление документации для публичных методов Обеспечение соответствия код-стайлу проекта Влияние на готовность: средний приоритет. Качество кода важно для поддерживаемости, но не блокирует деплой, если текущий код работает. План реализации по шагам Проведение code review всех изменений из предыдущих этапов Проанализировать все изменения, внесённые в Этапах 1 и 2: Rate Limiting middleware Валидаторы Обработчик ошибок Оптимизированные репозитории Пагинация Параллелизация запросов Зафиксировать места, требующие улучшения: Дублирование кода Неясное именование Отсутствие документации Нарушения код-стайла Устранение дублирования кода Найти дублирующиеся фрагменты кода: Общая логика обработки ошибок Общая логика валидации Общая логика маппинга данных Общая логика форматирования ответов Вынести дублирующийся код в утилиты или общие функции: Создать утилиты в src/shared/utils/ Создать общие функции в соответствующих модулях Обновить все места использования для использования общих функций Улучшение именования переменных и функций Проанализировать именование во всех модулях: Переменные должны иметь понятные имена Функции должны иметь понятные имена с глаголами Константы должны быть в UPPER_CASE Переименовать неясные имена: Использовать полные слова вместо аббревиатур Использовать описательные имена Следовать конвенциям проекта Добавление JSDoc комментариев к публичным методам Для каждого публичного метода добавить JSDoc комментарии: Описание назначения метода Описание параметров (@param) Описание возвращаемого значения (@returns) Описание возможных исключений (@throws) Примеры использования (если необходимо) Начать с критичных модулей: Контроллеры Use cases Репозитории Middleware Проверка обработки ошибок Убедиться, что все ошибки обрабатываются корректно: Все ошибки логируются Все ошибки возвращаются в едином формате Нет необработанных исключений Убедиться, что используется централизованный обработчик ошибок (если BE-1.4 выполнен) Проверка соответствия код-стайлу проекта Запустить ESLint: npm run lint Исправить все предупреждения и ошибки: Проблемы с форматированием Проблемы с использованием переменных Проблемы с типами Проблемы с безопасностью Убедиться, что код соответствует конвенциям проекта Финальная проверка качества кода Запустить все тесты: npm test Убедиться, что все тесты проходят Проверить сборку проекта: npm run build Проверить запуск проекта локально Обновление документации Обновить README.md с информацией о код-стайле проекта Задокументировать конвенции именования Указать рекомендации по написанию кода Проверки и тесты Критичные проверки: Дублирование кода устранено Именование улучшено JSDoc комментарии добавлены Код соответствует код-стайлу проекта Тестирование: Unit-тесты: Все существующие unit-тесты должны проходить При необходимости обновить тесты после рефакторинга Интеграционные тесты: Все существующие интеграционные тесты должны проходить Проверить работу всех функций после рефакторинга Ручное тестирование: Проверить работу всех эндпоинтов Проверить работу всех функций Метрики и логи: Проверить, что логирование работает корректно после рефакторинга Проверить, что нет новых предупреждений или ошибок Риски Регрессия после рефакторинга: Митигация: тщательно тестировать после каждого изменения, использовать git для отката при проблемах Проблемы с совместимостью после рефакторинга: Митигация: сохранить сигнатуры публичных методов, протестировать все места использования Обновление статуса После выполнения: Дублирование кода устранено Именование улучшено JSDoc комментарии добавлены Код соответствует код-стайлу проекта Все тесты проходят Статус: план реализации согласован, можно приступать к внесению изменений в код. Резюме по результатам Этапа 3 Выполненные задачи BE-3.1 — Обновление зависимостей (patch, minor, major версии) BE-3.2 — Улучшение CORS конфигурации для поддержки множественных origins BE-3.3 — Добавление request logging middleware для всех HTTP запросов BE-3.4 — Оптимизация connection pooling для продакшена BE-3.5 — Рефакторинг и улучшение качества кода Изменения в системе Стабильность и надёжность: Зависимости обновлены до актуальных версий, уязвимости устранены Connection pooling оптимизирован, мониторинг использования пула добавлен Качество кода улучшено, дублирование устранено Прозрачность (мониторинг, метрики, логирование): Все HTTP-запросы логируются с временем выполнения и статус-кодами Мониторинг использования пула соединений добавлен Логирование настраивается в зависимости от окружения Уровень технического долга: Зависимости обновлены, breaking changes задокументированы Дублирование кода устранено, код рефакторен JSDoc комментарии добавлены к публичным методам Удобство сопровождения и отладки: Код документирован и следует код-стайлу проекта Логирование улучшено для отладки CORS настроен гибко через переменные окружения Готовность к продакшену Готовность повысилась с 85–90% до 90–95% (по оценке из PRODUCTION_READINESS_PLAN.md). Задачи среднего приоритета выполнены, стабильность, наблюдаемость и качество кода улучшены. Критерии перехода к Этапу 4 Согласно PRODUCTION_READINESS_PLAN.md, критерии перехода от Этапа 3 к Этапу 4: Оптимизации завершены Мониторинг настроен Готовность ≥ 90% После выполнения BE-3.1, BE-3.2, BE-3.3, BE-3.4 и BE-3.5 эти критерии должны быть выполнены. Если все задачи завершены, тесты проходят и готовность достигла 90–95%, можно переходить к Этапу 4. Следующие шаги После завершения Этапа 3 переходим к Этапу 4: Улучшения качества, мониторинг и документация, начиная с BE-4.1 (Добавление метрик и мониторинга).

Реализация плана доведения бэкенда до продакшена — Этап 4 Этап 4: Улучшения качества, мониторинг и документация Состав этапа Этап 4 включает 7 задач: BE-4.1 — Добавить метрики и мониторинг (Prometheus, Grafana) (1 день) BE-4.2 — Расширить health checks (ready, live endpoints) (4 часа) BE-4.3 — Добавить Swagger/OpenAPI документацию для API (1 день) BE-4.4 — Улучшить тестовое покрытие (unit, integration, E2E) (2 дня) BE-4.5 — Настроить CI/CD pipeline для автоматизации процессов (1 день) BE-4.6 — Создать документацию для продакшена (DEPLOYMENT, MONITORING, TROUBLESHOOTING) (1 день) BE-4.7 — Провести нагрузочное тестирование и security audit (1 день) Цель этапа Добавить мониторинг, метрики, документацию и финальные проверки для выхода в продакшен: Метрики и мониторинг: сбор и экспорт метрик производительности, ошибок, использования ресурсов Финальные проверки и smoke-тесты: нагрузочное тестирование, security audit, финальный code review Документация API: Swagger/OpenAPI для разработчиков и интеграторов Финальный чек-лист готовности: критерии для деплоя в продакшен После завершения готовность должна достичь 100%. Связь с предыдущими этапами Этап 0: подготовлена среда, есть тестовая БД и инструменты Этап 1: устранены блокеры безопасности и стабильности (Rate Limiting, валидация, обработка ошибок) Этап 2: оптимизированы запросы к БД, добавлена пагинация, улучшена производительность Этап 3: улучшены стабильность, наблюдаемость и качество кода Этап 4 опирается на: Rate Limiting (BE-1.1) — для метрик по заблокированным запросам Централизованную обработку ошибок (BE-1.4) — для метрик по ошибкам Request logging middleware (BE-3.3) — для метрик по HTTP-запросам Оптимизированные запросы к БД (BE-2.1, BE-2.5) — для метрик производительности БД Мониторинг connection pooling (BE-3.4) — для метрик использования пула соединений Валидацию входных данных (BE-1.2) — для документации API с примерами валидации Этап 4 завершает подготовку к продакшену: добавляет наблюдаемость, документацию и финальные проверки. BE-4.1 — Добавление метрик и мониторинга (Prometheus, Grafana) Цель задачи Закрыть риски наблюдаемости и операционной готовности: Отсутствие метрик производительности в реальном времени Сложность диагностики проблем без данных Отсутствие алертов при деградации Невозможность отслеживать тренды и планировать масштабирование Влияние на готовность: высокий приоритет. Метрики и мониторинг критичны для продакшена, позволяют отслеживать состояние системы и быстро реагировать на проблемы. План реализации по шагам Аудит текущего состояния метрик и мониторинга Проверить наличие существующих метрик или мониторинга Проверить наличие /metrics endpoint (если есть) Зафиксировать, какие метрики уже собираются (если есть) Определить, какие метрики критичны для продакшена Установка пакета prom-client Перейти в backend/ Установить prom-client: npm install prom-client Проверить версию в package.json Убедиться, что пакет добавлен в dependencies Создание модуля для инициализации метрик Создать src/shared/metrics/index.ts Импортировать prom-client и создать Registry для метрик Экспортировать Registry для использования в других модулях Создать функцию инициализации метрик Добавление HTTP-метрик Создать метрики для HTTP-запросов: http_requests_total — общее количество HTTP-запросов (counter) http_request_duration_seconds — время выполнения HTTP-запросов (histogram) http_request_size_bytes — размер запросов (histogram, опционально) http_response_size_bytes — размер ответов (histogram, опционально) Интегрировать метрики с request logging middleware (если BE-3.3 выполнен): Записывать метрики в middleware для каждого запроса Использовать labels для группировки по методу, пути, статус-коду Если request logging middleware ещё не выполнен — добавить запись метрик напрямую в middleware Добавление метрик БД Создать метрики для операций с БД: db_queries_total — общее количество запросов к БД (counter) db_query_duration_seconds — время выполнения запросов к БД (histogram) db_errors_total — количество ошибок БД (counter) db_pool_active_connections — количество активных соединений (gauge) db_pool_idle_connections — количество простаивающих соединений (gauge) Интегрировать метрики с репозиториями: Записывать метрики в методах репозиториев Использовать labels для группировки по типу операции (select, insert, update, delete) Интегрировать метрики с мониторингом connection pooling (если BE-3.4 выполнен): Использовать данные мониторинга пула для метрик db_pool_* Добавление метрик Redis Создать метрики для операций с Redis: redis_operations_total — общее количество операций Redis (counter) redis_operation_duration_seconds — время выполнения операций Redis (histogram) redis_errors_total — количество ошибок Redis (counter) redis_connection_status — статус подключения к Redis (gauge: 1 = подключен, 0 = отключен) Интегрировать метрики с RedisCacheService: Записывать метрики в методах кеша Использовать labels для группировки по типу операции (get, set, delete) Добавление метрик использования ресурсов Создать метрики для использования ресурсов: process_cpu_user_seconds_total — использование CPU пользователем (counter) process_cpu_system_seconds_total — использование CPU системой (counter) process_resident_memory_bytes — использование памяти (gauge) nodejs_heap_size_total_bytes — размер heap Node.js (gauge) nodejs_heap_size_used_bytes — использованный размер heap Node.js (gauge) Использовать встроенные метрики prom-client для Node.js Создание endpoint /metrics для экспорта метрик Открыть src/index.ts Импортировать Registry метрик Добавить endpoint /metrics: Использовать registry.metrics() для получения метрик в формате Prometheus Вернуть метрики с правильным Content-Type (text/plain; version=0.0.4) Не требовать аутентификации для /metrics (для Prometheus) Протестировать доступность endpoint Настройка Prometheus для сбора метрик (если доступен) Создать конфигурацию Prometheus (prometheus.yml или аналогичный файл): Настроить scrape_config для сбора метрик с backend Указать URL endpoint /metrics Настроить интервал сбора метрик (например, 15 секунд) Протестировать сбор метрик Prometheus Проверить, что метрики появляются в Prometheus Создание базовых Grafana дашбордов (если доступен) Создать дашборд для HTTP-метрик: График количества запросов по времени График времени ответа (p50, p95, p99) График количества ошибок по статус-кодам Создать дашборд для метрик БД: График количества запросов к БД График времени выполнения запросов График использования пула соединений Создать дашборд для метрик Redis: График количества операций Redis График времени выполнения операций Статус подключения к Redis Создать дашборд для метрик использования ресурсов: График использования CPU График использования памяти График размера heap Node.js Добавление алертов для критичных метрик Настроить алерты в Prometheus (если доступен): Высокий процент ошибок (> 5%): rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05 Медленные запросы (p95 > 1 секунды): histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1 Высокое использование ресурсов (CPU > 80%): rate(process_cpu_user_seconds_total[5m]) > 0.8 Высокое использование памяти (> 80%): process_resident_memory_bytes / <total_memory> > 0.8 Проблемы с БД (много активных соединений): db_pool_active_connections / db_pool_max_connections > 0.9 Настроить уведомления для алертов (email, Slack, PagerDuty и т.д.) Тестирование сбора и экспорта метрик Протестировать сбор метрик: Отправить несколько запросов к API Проверить, что метрики обновляются Проверить endpoint /metrics Протестировать экспорт метрик: Проверить формат метрик Prometheus Проверить, что все метрики присутствуют Проверить labels метрик Обновление документации Обновить README.md с информацией о метриках Задокументировать доступные метрики Указать, как настроить Prometheus и Grafana Указать, как настроить алерты Проверки и тесты Критичные проверки: Метрики собираются для всех компонентов (HTTP, БД, Redis, ресурсы) Endpoint /metrics доступен и возвращает метрики в формате Prometheus Метрики обновляются в реальном времени Алерты настроены для критичных метрик Тестирование: Интеграционные тесты: Тесты для сбора метрик при различных запросах Тесты для экспорта метрик через endpoint /metrics Тесты для корректности формата метрик Ручное тестирование: Проверить endpoint /metrics через браузер или curl Проверить, что метрики обновляются при запросах Проверить работу Prometheus и Grafana (если доступны) Метрики и логи: Отслеживать сбор метрик в реальном времени Проверить корректность значений метрик Проверить работу алертов Риски Некорректные метрики или ложные алерты: Митигация: тщательно протестировать метрики, настроить разумные пороги для алертов, использовать тестовую среду для проверки Раскрытие лишней информации в метриках: Митигация: не включать чувствительные данные в labels метрик, использовать общие названия для путей (например, /api/v1/routes/:id вместо конкретных ID) Нагрузка от метрик: Митигация: метрики собираются асинхронно, не блокируют основной поток, при необходимости оптимизировать сбор метрик Обновление статуса После выполнения: Метрики собираются для всех компонентов (HTTP, БД, Redis, ресурсы) Endpoint /metrics создан и работает Prometheus и Grafana настроены (если доступны) Алерты настроены для критичных метрик Документация обновлена Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-4.2 — Расширение health checks (ready, live endpoints) Цель задачи Закрыть риски операционной готовности и интеграции с оркестраторами: Отсутствие детальных health checks для различных компонентов системы Невозможность проверить готовность системы к обработке запросов Отсутствие интеграции с оркестраторами (Kubernetes, Docker Swarm) Сложность диагностики проблем с зависимостями Влияние на готовность: высокий приоритет. Health checks критичны для продакшена, особенно при использовании оркестраторов и автоматического масштабирования. План реализации по шагам Анализ текущего состояния health checks Открыть src/index.ts или src/presentation/controllers/HealthController.ts Изучить существующий /health endpoint Зафиксировать, какие проверки уже выполняются Определить, какие проверки нужно добавить Расширение существующего /health endpoint Обновить существующий /health endpoint для включения детальных проверок: Проверка подключения к PostgreSQL: Выполнить простой запрос (например, SELECT 1) Зафиксировать время ответа Вернуть статус подключения Проверка подключения к Redis: Выполнить PING команду Зафиксировать время ответа Вернуть статус подключения Проверка доступности OData API (опционально): Выполнить тестовый запрос к OData API Зафиксировать время ответа Вернуть статус доступности Проверка доступности графа маршрутов: Проверить наличие графа в Redis (если BE-1.3 выполнен) Вернуть статус доступности графа Вернуть детальный ответ с статусом каждого компонента: { "status": "ok" | "degraded" | "error", "timestamp": "2024-12-19T12:00:00Z", "checks": { "postgres": { "status": "ok", "responseTimeMs": 5 }, "redis": { "status": "ok", "responseTimeMs": 2 }, "odata": { "status": "ok", "responseTimeMs": 100 }, "graph": { "status": "ok", "version": "1.0.0" } } } Создание endpoint /health/ready для проверки готовности Создать новый endpoint /health/ready Реализовать проверки готовности к обработке запросов: PostgreSQL подключен и отвечает Redis подключен и отвечает Граф маршрутов доступен (если необходим для работы) Вернуть статус 200, если система готова, или 503, если не готова Использовать для проверки готовности перед началом обработки запросов Создание endpoint /health/live для проверки живости Создать новый endpoint /health/live Реализовать минимальную проверку живости сервиса: Проверить, что процесс работает Вернуть статус 200, если процесс жив Не проверять зависимости (БД, Redis), только живость процесса Использовать для проверки живости сервиса оркестраторами Интеграция с оркестраторами (Kubernetes, Docker Swarm) Обновить docker-compose.yml для использования health checks: Добавить healthcheck для сервиса backend: Использовать /health/live для проверки живости Использовать /health/ready для проверки готовности Настроить интервал проверки (например, 30 секунд) Настроить таймаут проверки (например, 10 секунд) Настроить количество попыток (например, 3) Обновить Kubernetes манифесты (если используются): Добавить livenessProbe с использованием /health/live Добавить readinessProbe с использованием /health/ready Настроить интервалы и таймауты Тестирование health checks при различных состояниях системы Протестировать /health при нормальной работе: Все компоненты доступны Все проверки проходят успешно Протестировать /health при деградации: Один из компонентов недоступен (например, Redis) Проверки показывают статус "degraded" Протестировать /health/ready при недоступности критичных компонентов: PostgreSQL недоступен — должен вернуть 503 Redis недоступен — должен вернуть 503 (если критичен) Протестировать /health/live при работе процесса: Процесс работает — должен вернуть 200 Процесс не работает — оркестратор должен обнаружить это Обновление документации Обновить README.md с информацией о health checks Задокументировать все health check endpoints Указать, как использовать health checks с оркестраторами Указать рекомендации по настройке интервалов и таймаутов Проверки и тесты Критичные проверки: Все health check endpoints работают корректно Проверки компонентов выполняются правильно Статусы отражают реальное состояние системы Интеграция с оркестраторами работает Тестирование: Интеграционные тесты: Тесты для /health при различных состояниях системы Тесты для /health/ready при готовности и неготовности Тесты для /health/live при работе процесса Ручное тестирование: Проверить health checks через Postman или curl Проверить работу при недоступности компонентов Проверить интеграцию с Docker Compose Метрики и логи: Логировать результаты health checks (опционально) Отслеживать время ответа health checks Риски Некорректное отражение состояния системы: Митигация: тщательно протестировать health checks при различных состояниях, использовать реалистичные проверки Проблемы с производительностью health checks: Митигация: использовать быстрые проверки, не выполнять тяжёлые операции в health checks, использовать таймауты Обновление статуса После выполнения: Health checks расширены и работают корректно Endpoints /health/ready и /health/live созданы Интеграция с оркестраторами настроена Тесты написаны и проходят Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-4.3 — Добавление Swagger/OpenAPI документации для API Цель задачи Закрыть риски документации и интеграции: Отсутствие актуальной документации API для разработчиков Сложность интеграции для внешних клиентов Неясность форматов запросов и ответов Отсутствие примеров использования API Влияние на готовность: средний приоритет. Документация API важна для продакшена, но не блокирует деплой, если текущая документация достаточна. План реализации по шагам Установка пакетов для Swagger/OpenAPI Перейти в backend/ Установить swagger-jsdoc: npm install swagger-jsdoc Установить swagger-ui-express: npm install swagger-ui-express Установить типы: npm install --save-dev @types/swagger-jsdoc @types/swagger-ui-express Проверить версии в package.json Создание базовой конфигурации Swagger Создать src/presentation/swagger/config.ts Настроить базовую конфигурацию Swagger: Информация о API (название, версия, описание) Информация о серверах (development, staging, production) Базовые схемы безопасности (если используется аутентификация) Настройки для swagger-jsdoc (пути к файлам с JSDoc комментариями) Экспортировать конфигурацию для использования в приложении Добавление JSDoc комментариев к контроллерам Для каждого контроллера в src/presentation/controllers/: Добавить JSDoc комментарии с описанием эндпоинтов: @swagger теги для группировки эндпоинтов Описание эндпоинта Параметры запроса (query, path, body): Тип параметра Обязательность Описание Примеры значений Формат ответа: Структура успешного ответа Структура ответа с ошибкой Примеры ответов Коды ошибок: 400 — ошибка валидации 404 — ресурс не найден 500 — внутренняя ошибка сервера Примеры запросов и ответов Начать с критичных контроллеров: RouteBuilderController.ts — поиск маршрутов RiskController.ts — оценка риска маршрута CitiesController.ts — список городов HealthController.ts — health checks Использование Zod-схем для генерации схем данных (опционально) Если BE-1.2 выполнен и используются Zod-схемы: Изучить возможность использования Zod-схем для генерации Swagger-схем Использовать библиотеку zod-to-openapi или аналогичную (если доступна) Или вручную описать схемы в Swagger на основе Zod-схем Если Zod-схемы не используются — описать схемы вручную в Swagger Настройка Swagger UI на /api-docs Открыть src/index.ts Импортировать swagger-ui-express и конфигурацию Swagger Настроить Swagger UI: Использовать swaggerUi.setup() для настройки UI Указать путь к документации (например, /api-docs) Настроить опции UI (темы, размеры и т.д.) Добавить middleware для Swagger UI перед роутами API Протестировать доступность Swagger UI Добавление описания схем данных Описать схемы данных для запросов и ответов: Схема для поиска маршрутов (RouteSearchRequest) Схема для ответа с маршрутами (RouteSearchResponse) Схема для оценки риска (RiskAssessmentRequest, RiskAssessmentResponse) Схема для списка городов (CitiesResponse) Схема для ошибок (ErrorResponse) Использовать компоненты Swagger для переиспользования схем Тестирование отображения документации Открыть Swagger UI в браузере Проверить отображение всех эндпоинтов Проверить корректность описаний параметров Проверить корректность примеров запросов и ответов Проверить работу "Try it out" для тестирования API Обновление README с ссылкой на документацию API Обновить README.md: Добавить раздел "API Documentation" Указать URL для доступа к Swagger UI (например, http://localhost:5000/api-docs) Указать, как использовать документацию Указать рекомендации по обновлению документации Проверки и тесты Критичные проверки: Swagger UI доступен и отображается корректно Все эндпоинты задокументированы Описания параметров и ответов корректны Примеры запросов и ответов работают Тестирование: Ручное тестирование: Проверить Swagger UI в браузере Проверить отображение всех эндпоинтов Проверить работу "Try it out" для тестирования API Проверить корректность примеров Валидация документации: Проверить, что документация соответствует реальному поведению API Проверить, что все параметры описаны Проверить, что все коды ошибок задокументированы Метрики и логи: Отслеживать использование Swagger UI (опционально) Логировать случаи использования "Try it out" Риски Рассинхронизация документации и реального API: Митигация: обновлять документацию при каждом изменении API, использовать CI/CD для проверки синхронизации, проводить регулярные ревью документации Раскрытие лишней информации в документации: Митигация: не включать чувствительные данные в примеры, использовать общие примеры, не документировать внутренние эндпоинты Обновление статуса После выполнения: Swagger/OpenAPI документация создана и доступна Все эндпоинты задокументированы Swagger UI настроен и работает Документация обновлена в README Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-4.4 — Улучшение тестового покрытия (unit, integration, E2E) Цель задачи Закрыть риски качества и надёжности: Недостаточное покрытие тестами критичных модулей Отсутствие тестов для новых функций (валидация, rate limiting, error handling) Отсутствие E2E-тестов для основных сценариев Невозможность уверенно деплоить без достаточного покрытия Влияние на готовность: высокий приоритет. Тестовое покрытие критично для продакшена, обеспечивает уверенность в стабильности системы. План реализации по шагам Анализ текущего покрытия тестами Запустить npm run test:coverage для анализа покрытия Зафиксировать текущий процент покрытия для каждого модуля Определить критические модули с низким покрытием: Контроллеры Use cases Репозитории Middleware Создать документ с анализом покрытия Добавление unit-тестов для валидаторов Создать src/__tests__/validators/ (если не существует) Для каждого валидатора (если BE-1.2 выполнен): Создать unit-тесты для всех Zod-схем Тесты для валидных данных Тесты для невалидных данных Тесты для граничных значений Убедиться, что покрытие валидаторов ≥ 90% Добавление unit-тестов для middleware Создать src/__tests__/middleware/ (если не существует) Тесты для rate limiting middleware (если BE-1.1 выполнен): Тесты для работы лимитов Тесты для различных лимитов для разных эндпоинтов Тесты для обработки превышения лимитов Тесты для error handling middleware (если BE-1.4 выполнен): Тесты для обработки различных типов ошибок Тесты для форматирования ответов об ошибках Тесты для скрытия деталей ошибок в продакшене Тесты для request logging middleware (если BE-3.3 выполнен): Тесты для логирования запросов Тесты для фильтрации чувствительных данных Добавление unit-тестов для утилит Создать src/__tests__/utils/ (если не существует) Тесты для утилиты пагинации (если BE-2.2 выполнен): Тесты для валидации параметров Тесты для вычисления offset Тесты для создания метаданных пагинации Тесты для других утилит (форматирование, валидация и т.д.) Добавление интеграционных тестов для критичных путей Создать src/__tests__/integration/ (если не существует) Интеграционные тесты для поиска маршрутов: Тесты для успешного поиска маршрута Тесты для обработки ошибок при поиске Тесты для работы с графом маршрутов Интеграционные тесты для оценки риска маршрута: Тесты для успешной оценки риска Тесты для обработки ошибок при оценке Интеграционные тесты для работы с кешем: Тесты для кеширования данных Тесты для инвалидации кеша Тесты для работы Redis под нагрузкой Добавление E2E-тестов для основных сценариев Создать src/__tests__/e2e/ (если не существует) E2E-тесты для полного цикла поиска маршрута: Запрос на поиск маршрута Валидация входных данных Обработка Rate Limiting Построение маршрута через граф Возврат результата E2E-тесты для обработки ошибок: Обработка невалидных данных Обработка превышения Rate Limit Обработка ошибок БД/Redis E2E-тесты для health checks: Проверка работы всех health check endpoints Проверка работы при различных состояниях системы Настройка минимального порога покрытия Открыть jest.config.js Настроить минимальный порог покрытия: Общее покрытие: ≥ 70% Покрытие для критичных модулей (контроллеры, use cases, middleware): ≥ 80% Покрытие для утилит: ≥ 90% Настроить проверку покрытия в CI/CD (если BE-4.5 будет выполнен) Настройка CI/CD для автоматического запуска тестов Если BE-4.5 будет выполнен — настроить автоматический запуск тестов в CI/CD Если BE-4.5 ещё не выполнен — подготовить конфигурацию для будущей интеграции Убедиться, что тесты запускаются при каждом коммите Убедиться, что проверка покрытия выполняется автоматически Обновление документации Обновить README.md с информацией о тестах Задокументировать, как запускать тесты Указать требования к покрытию тестами Указать рекомендации по написанию тестов Проверки и тесты Критичные проверки: Покрытие тестами ≥ 70% для всего проекта Покрытие тестами ≥ 80% для критичных модулей Все тесты проходят стабильно E2E-тесты покрывают основные сценарии Тестирование: Запуск всех тестов: Unit-тесты: npm run test:unit Интеграционные тесты: npm run test:integration E2E-тесты: npm run test:e2e Все тесты: npm test Проверка покрытия: npm run test:coverage Убедиться, что покрытие соответствует требованиям Стабильность тестов: Запустить тесты несколько раз Убедиться, что тесты проходят стабильно Метрики и логи: Отслеживать покрытие тестами Отслеживать количество пройденных/проваленных тестов Логировать результаты тестов Риски Нестабильные тесты: Митигация: использовать моки для внешних зависимостей, изолировать тесты, использовать детерминированные данные Недостаточное покрытие критичных модулей: Митигация: приоритизировать тесты для критичных модулей, использовать минимальные пороги покрытия Обновление статуса После выполнения: Тестовое покрытие ≥ 70% для всего проекта Тестовое покрытие ≥ 80% для критичных модулей E2E-тесты покрывают основные сценарии CI/CD настроен для автоматического запуска тестов Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-4.5 — Настройка CI/CD pipeline для автоматизации процессов Цель задачи Закрыть риски автоматизации и качества: Отсутствие автоматической проверки кода перед деплоем Ручной запуск тестов и проверок Отсутствие автоматизации сборки и деплоя Риск деплоя некорректного кода Влияние на готовность: средний приоритет. CI/CD важен для продакшена, но не блокирует деплой, если процессы можно выполнять вручную. План реализации по шагам Выбор платформы для CI/CD Определить доступную платформу (GitHub Actions, GitLab CI, Jenkins, CircleCI и т.д.) Изучить возможности платформы Зафиксировать выбор платформы Создание базовой конфигурации CI/CD Создать конфигурационный файл для выбранной платформы: GitHub Actions: .github/workflows/ci.yml GitLab CI: .gitlab-ci.yml Jenkins: Jenkinsfile Настроить базовую структуру pipeline: Триггеры (push, pull request) Переменные окружения Кеширование зависимостей Настройка этапа установки зависимостей Добавить этап установки зависимостей: Установка Node.js (версия из .nvmrc или package.json) Установка зависимостей через npm ci Кеширование node_modules для ускорения сборок Настройка этапа запуска линтера Добавить этап запуска линтера: Запуск ESLint: npm run lint Проверка форматирования кода (если используется Prettier) Завершение pipeline с ошибкой при наличии ошибок линтера Настройка этапа запуска тестов Добавить этап запуска тестов: Запуск всех тестов: npm test Генерация отчёта о покрытии: npm run test:coverage Публикация отчёта о покрытии (опционально) Завершение pipeline с ошибкой при падении тестов Настройка этапа проверки покрытия тестами Добавить этап проверки покрытия: Проверка минимального порога покрытия (≥ 70%) Завершение pipeline с ошибкой при недостаточном покрытии Публикация отчёта о покрытии (опционально) Настройка этапа сборки проекта Добавить этап сборки проекта: Компиляция TypeScript: npm run build Проверка наличия ошибок компиляции Завершение pipeline с ошибкой при ошибках компиляции Настройка этапа деплоя (опционально) Если требуется автоматический деплой: Настроить деплой только для определённых веток (например, main) Настроить деплой только после успешного прохождения всех проверок Настроить секреты для доступа к продакшен-среде Настроить уведомления о результатах деплоя Настройка уведомлений о результатах сборки Настроить уведомления: Email-уведомления (опционально) Slack-уведомления (опционально) Уведомления в GitHub/GitLab (встроенные) Уведомлять о: Успешных сборках Проваленных сборках Результатах деплоя (если настроен) Тестирование pipeline на тестовой ветке Создать тестовую ветку Запустить pipeline на тестовой ветке Проверить работу всех этапов Исправить проблемы, если они возникли Обновление документации Обновить README.md с информацией о CI/CD Задокументировать процесс работы pipeline Указать, как проверить статус сборки Указать рекомендации по работе с CI/CD Проверки и тесты Критичные проверки: Pipeline запускается при каждом push и pull request Все этапы выполняются корректно Pipeline завершается с ошибкой при наличии проблем Уведомления работают Тестирование: Тестирование pipeline: Создать тестовую ветку с изменениями Проверить запуск pipeline Проверить работу всех этапов Проверить обработку ошибок Тестирование деплоя (если настроен): Проверить деплой на тестовую среду Проверить работу после деплоя Метрики и логи: Отслеживать время выполнения pipeline Отслеживать количество успешных/проваленных сборок Логировать результаты сборки Риски Проблемы с производительностью pipeline: Митигация: использовать кеширование зависимостей, оптимизировать этапы, использовать параллельное выполнение этапов Проблемы с доступностью CI/CD платформы: Митигация: использовать надёжную платформу, иметь план резервного копирования Обновление статуса После выполнения: CI/CD pipeline настроен и работает Все этапы (установка зависимостей, линтер, тесты, сборка) выполняются автоматически Уведомления настроены Документация обновлена Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-4.6 — Создание документации для продакшена Цель задачи Закрыть риски операционной готовности и сопровождения: Отсутствие инструкций по деплою для операторов Отсутствие описания метрик и алертов для мониторинга Отсутствие руководства по устранению типичных проблем Сложность сопровождения системы без документации Влияние на готовность: средний приоритет. Документация важна для продакшена, но не блокирует деплой, если операторы знают систему. План реализации по шагам Обновление README.md с инструкциями по деплою Открыть backend/README.md Добавить раздел "Deployment": Краткое описание процесса деплоя Ссылка на детальную документацию (DEPLOYMENT.md) Основные шаги деплоя Обновить другие разделы при необходимости Создание DEPLOYMENT.md с детальными инструкциями Создать backend/DEPLOYMENT.md Добавить раздел "Требования к окружению": Версия Node.js Версия PostgreSQL Версия Redis Другие зависимости Добавить раздел "Переменные окружения": Список всех переменных окружения Описание каждой переменной Примеры значений Рекомендации по настройке для различных окружений Добавить раздел "Процесс деплоя": Подготовка окружения Установка зависимостей Применение миграций БД Запуск приложения Проверка работоспособности Добавить раздел "Проверка работоспособности после деплоя": Проверка health checks Проверка основных эндпоинтов Проверка метрик Проверка логов Создание MONITORING.md с описанием метрик и алертов Создать backend/MONITORING.md Добавить раздел "Метрики": Описание всех доступных метрик Группировка метрик по категориям (HTTP, БД, Redis, ресурсы) Описание labels метрик Рекомендации по интерпретации метрик Добавить раздел "Алерты": Описание всех настроенных алертов Пороги для каждого алерта Действия при срабатывании алертов Рекомендации по настройке алертов Добавить раздел "Дашборды": Описание доступных Grafana дашбордов (если настроены) Рекомендации по использованию дашбордов Добавить раздел "Логирование": Описание формата логов Уровни логирования Рекомендации по хранению и анализу логов Создание TROUBLESHOOTING.md с описанием типичных проблем Создать backend/TROUBLESHOOTING.md Добавить раздел "Типичные проблемы": Проблемы с подключением к БД: Симптомы Причины Решения Проблемы с подключением к Redis: Симптомы Причины Решения Проблемы с производительностью: Симптомы Причины Решения Проблемы с памятью: Симптомы Причины Решения Добавить раздел "Диагностика": Как собрать информацию для диагностики Какие логи проверить Какие метрики посмотреть Как воспроизвести проблему Добавление диаграмм архитектуры (если необходимо) Создать диаграммы архитектуры системы: Общая архитектура (компоненты, их взаимодействие) Архитектура данных (БД, Redis, MinIO) Архитектура API (эндпоинты, их зависимости) Сохранить диаграммы в backend/docs/ или аналогичной директории Добавить ссылки на диаграммы в документацию Обновление существующей документации Проверить актуальность всей существующей документации Обновить устаревшие разделы Добавить ссылки на новую документацию Проверки и тесты Критичные проверки: Вся документация создана и актуальна Инструкции по деплою корректны Описания метрик и алертов соответствуют реальности Руководство по устранению проблем полезно Тестирование: Ручное тестирование: Попробовать следовать инструкциям по деплою Проверить корректность всех инструкций Проверить актуальность примеров Валидация документации: Проверить, что документация соответствует реальному поведению системы Проверить, что все переменные окружения задокументированы Проверить, что все метрики описаны Метрики и логи: Отслеживать использование документации (опционально) Риски Устаревание документации: Митигация: обновлять документацию при каждом изменении системы, проводить регулярные ревью документации, использовать CI/CD для проверки актуальности Неточность инструкций: Митигация: тестировать инструкции на реальном окружении, получать обратную связь от операторов Обновление статуса После выполнения: Документация для продакшена создана (DEPLOYMENT.md, MONITORING.md, TROUBLESHOOTING.md) README.md обновлён с инструкциями по деплою Диаграммы архитектуры добавлены (если необходимо) Вся документация актуальна Статус: план реализации согласован, можно приступать к внесению изменений в код. BE-4.7 — Проведение нагрузочного тестирования и security audit Цель задачи Закрыть риски производительности и безопасности: Неизвестная производительность системы под нагрузкой Наличие узких мест, которые могут привести к деградации Наличие уязвимостей безопасности Отсутствие уверенности в готовности к продакшену Влияние на готовность: критичный приоритет. Нагрузочное тестирование и security audit критичны для продакшена, являются финальными проверками перед деплоем. План реализации по шагам Подготовка к нагрузочному тестированию Выбрать инструмент для нагрузочного тестирования: artillery — простой и удобный k6 — мощный и гибкий Другие инструменты по выбору Установить выбранный инструмент Подготовить тестовую среду, максимально похожую на продакшен Создание сценариев нагрузочного тестирования Создать сценарии для основных эндпоинтов: Поиск маршрутов (/api/v1/routes/search) Оценка риска маршрута (/api/v1/routes/risk/assess) Список городов (/api/v1/cities) Health checks (/health) Настроить параметры нагрузки: Количество виртуальных пользователей Длительность теста Паттерн нагрузки (постоянная, пиковая, постепенное увеличение) Проведение нагрузочного тестирования Запустить нагрузочное тестирование для каждого сценария Измерить метрики производительности: Время ответа (p50, p95, p99) Количество запросов в секунду (RPS) Количество ошибок Использование ресурсов (CPU, память) Количество активных соединений с БД Зафиксировать результаты тестирования Анализ результатов и поиск узких мест Проанализировать результаты нагрузочного тестирования: Определить узкие места (медленные эндпоинты, высокое использование ресурсов) Определить проблемы с производительностью Определить проблемы с масштабируемостью Создать документ с анализом результатов Оптимизация найденных узких мест Для каждого найденного узкого места: Определить причину проблемы Разработать план оптимизации Реализовать оптимизацию Повторно протестировать для проверки улучшения Зафиксировать результаты оптимизации Проведение security audit Запустить npm audit для проверки уязвимостей в зависимостях: Проверить критичные уязвимости Проверить высокие уязвимости Устранить найденные уязвимости Проверить конфигурацию безопасности: Проверить настройки CORS Проверить настройки Rate Limiting Проверить обработку чувствительных данных Проверить валидацию входных данных Проверить обработку чувствительных данных: Убедиться, что пароли не логируются Убедиться, что токены не логируются Убедиться, что чувствительные данные фильтруются из логов Проведение финального code review Провести code review всех изменений из всех этапов: Проверить соответствие код-стайлу Проверить обработку ошибок Проверить безопасность кода Проверить производительность кода Зафиксировать найденные проблемы Исправить критичные проблемы Создание чек-листа для деплоя в продакшен Создать backend/PRODUCTION_DEPLOY_CHECKLIST.md Добавить чек-лист с пунктами: Все критичные блокеры устранены Все тесты проходят Покрытие тестами ≥ 70% Метрики и мониторинг настроены Health checks работают Документация актуальна Нагрузочное тестирование пройдено Security audit пройден Переменные окружения настроены Резервное копирование настроено Добавить возможность отмечать выполненные пункты Обновление документации Обновить DEPLOYMENT.md с результатами нагрузочного тестирования Обновить MONITORING.md с рекомендациями по мониторингу под нагрузкой Обновить TROUBLESHOOTING.md с типичными проблемами под нагрузкой Проверки и тесты Критичные проверки: Нагрузочное тестирование пройдено успешно Узкие места найдены и оптимизированы Security audit пройден, уязвимости устранены Code review проведён, проблемы исправлены Тестирование: Нагрузочное тестирование: Тестирование всех основных эндпоинтов Измерение метрик производительности Проверка стабильности под нагрузкой Security audit: Проверка уязвимостей в зависимостях Проверка конфигурации безопасности Проверка обработки чувствительных данных Метрики и логи: Зафиксировать результаты нагрузочного тестирования Зафиксировать результаты security audit Отслеживать метрики производительности Риски Выявление критичных проблем при нагрузочном тестировании: Митигация: провести нагрузочное тестирование заранее, оставить время на оптимизацию, иметь план резервных решений Выявление критичных уязвимостей при security audit: Митигация: провести security audit заранее, оставить время на устранение уязвимостей, использовать автоматические инструменты проверки Обновление статуса После выполнения: Нагрузочное тестирование проведено, узкие места оптимизированы Security audit пройден, уязвимости устранены Code review проведён, проблемы исправлены Чек-лист для деплоя создан Статус: план реализации согласован, можно приступать к внесению изменений в код. Резюме по результатам Этапа 4 Выполненные задачи BE-4.1 — Добавление метрик и мониторинга (Prometheus, Grafana) BE-4.2 — Расширение health checks (ready, live endpoints) BE-4.3 — Добавление Swagger/OpenAPI документации для API BE-4.4 — Улучшение тестового покрытия (unit, integration, E2E) BE-4.5 — Настройка CI/CD pipeline для автоматизации процессов BE-4.6 — Создание документации для продакшена (DEPLOYMENT, MONITORING, TROUBLESHOOTING) BE-4.7 — Проведение нагрузочного тестирования и security audit Изменения в системе Метрики и мониторинг: HTTP-метрики (количество запросов, время ответа, статус-коды) Метрики БД (количество запросов, время выполнения, использование пула соединений) Метрики Redis (количество операций, время выполнения, статус подключения) Метрики использования ресурсов (CPU, память, heap Node.js) Endpoint /metrics для экспорта метрик в формате Prometheus Алерты для критичных метрик (высокая ошибка, медленные запросы, высокое использование ресурсов) Документация API: Swagger/OpenAPI документация для всех эндпоинтов Swagger UI доступен на /api-docs Описания параметров, ответов, кодов ошибок Примеры запросов и ответов Чек-листы и финальные проверки: Чек-лист для деплоя в продакшен (PRODUCTION_DEPLOY_CHECKLIST.md) Результаты нагрузочного тестирования Результаты security audit Финальный code review Финальная готовность к продакшену Готовность достигла 100% (по оценке из PRODUCTION_READINESS_PLAN.md). Выполнены условия для деплоя: Устранены все критичные блокеры (Этап 1) Оптимизирована производительность (Этап 2) Улучшены стабильность и качество кода (Этап 3) Настроены метрики и мониторинг (Этап 4) Создана документация (Этап 4) Проведены финальные проверки (Этап 4) Критерии выхода в продакшен Definition of Ready for Production: Все критичные блокеры устранены (Rate Limiting, валидация, обработка ошибок, утечки соединений) Производительность оптимизирована (явные поля в запросах, индексы, пагинация, параллелизация) Метрики и мониторинг настроены (Prometheus, Grafana, алерты) Health checks расширены и работают (/health, /health/ready, /health/live) API полностью задокументирован (Swagger/OpenAPI) Тестовое покрытие ≥ 70% (≥ 80% для критичных модулей) CI/CD pipeline настроен и работает Документация для продакшена создана (DEPLOYMENT.md, MONITORING.md, TROUBLESHOOTING.md) Нагрузочное тестирование пройдено, узкие места оптимизированы Security audit пройден, уязвимости устранены Финальный code review проведён, проблемы исправлены Чек-лист для деплоя выполнен Следующие шаги После завершения Этапа 4 система готова к деплою в продакшен. Все критерии готовности выполнены, метрики и мониторинг настроены, документация создана, финальные проверки пройдены. Можно приступать к деплою в продакшен-среду.

